{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "Give a brief description of the dataset you are using:\n",
    "\n",
    "The dataset describes the ecological footprint for 196 countries over a different range of years for each country. The data has 5 record types - Biocapacity (Biocap), Ecological Footprint Exports, Inports, Produced, Consumed (EFExports, EFImports, EFProd, EFCons) - and each record type has two possible measures - global hectares per capita (PerCap) and total global hectares (TotGHA), for a total of 10 record types.\n",
    "\n",
    "As quoted from the kaggle dataset data summary:\n",
    "\"The columns \"crop_land\" through \"carbon\" are the number of global hectares of this landtype either required to support consumption/production (Ecological Footprint of Consumption, Production), or that are supported by biological productivity (Biocapacity). The \"total\" column is the sum of these values.\"\n",
    "\n",
    "The dataset also includes the country's per capita GDP and population for each year.\n",
    "\n",
    "The link to the dataset is here: https://www.kaggle.com/footprintnetwork/national-footprint-accounts-2018\n",
    "\n",
    "Note that I have renamed the csv post-download from 'NFA 2018.csv' to 'NFA_2018.csv' to ensure no path confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>ISO alpha-3 code</th>\n",
       "      <th>UN_region</th>\n",
       "      <th>UN_subregion</th>\n",
       "      <th>year</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>Percapita GDP (2010 USD)</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>1.611286e-01</td>\n",
       "      <td>0.135023</td>\n",
       "      <td>0.083836</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.273741e-01</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>5.558130e+05</td>\n",
       "      <td>465763.337400</td>\n",
       "      <td>289190.662300</td>\n",
       "      <td>47320.224590</td>\n",
       "      <td>116139.598200</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.474227e+06</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>3.909225e-01</td>\n",
       "      <td>0.189137</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>1.112225e+00</td>\n",
       "      <td>1.730092e+00</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFConsTotGHA</td>\n",
       "      <td>1.348487e+06</td>\n",
       "      <td>652429.066600</td>\n",
       "      <td>4.327841</td>\n",
       "      <td>14272.803690</td>\n",
       "      <td>116139.598200</td>\n",
       "      <td>3.836620e+06</td>\n",
       "      <td>5.967954e+06</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFExportsPerCap</td>\n",
       "      <td>1.124910e-03</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.819043e-02</td>\n",
       "      <td>5.203676e-02</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFExportsTotGHA</td>\n",
       "      <td>3.880378e+03</td>\n",
       "      <td>7875.331688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1512.195296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.662329e+05</td>\n",
       "      <td>1.795008e+05</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFImportsPerCap</td>\n",
       "      <td>2.309189e-01</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.791121e-02</td>\n",
       "      <td>3.785406e-01</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFImportsTotGHA</td>\n",
       "      <td>7.965547e+05</td>\n",
       "      <td>194541.060900</td>\n",
       "      <td>4.327841</td>\n",
       "      <td>11426.058040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.032497e+05</td>\n",
       "      <td>1.305776e+06</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFProdPerCap</td>\n",
       "      <td>1.611286e-01</td>\n",
       "      <td>0.135023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>1.072504e+00</td>\n",
       "      <td>1.403588e+00</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1992</td>\n",
       "      <td>EFProdTotGHA</td>\n",
       "      <td>5.558130e+05</td>\n",
       "      <td>465763.337400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4358.940944</td>\n",
       "      <td>116139.598200</td>\n",
       "      <td>3.699604e+06</td>\n",
       "      <td>4.841678e+06</td>\n",
       "      <td>949.033</td>\n",
       "      <td>3449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>1.598552e-01</td>\n",
       "      <td>0.138346</td>\n",
       "      <td>0.085972</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.301759e-01</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>5.386591e+05</td>\n",
       "      <td>466181.595600</td>\n",
       "      <td>289695.836700</td>\n",
       "      <td>47293.877270</td>\n",
       "      <td>107720.238800</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.449551e+06</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>3.866109e-01</td>\n",
       "      <td>0.200749</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>5.352768e-01</td>\n",
       "      <td>1.158431e+00</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFConsTotGHA</td>\n",
       "      <td>1.302751e+06</td>\n",
       "      <td>676458.725700</td>\n",
       "      <td>36.034083</td>\n",
       "      <td>12858.191160</td>\n",
       "      <td>107720.238800</td>\n",
       "      <td>1.803706e+06</td>\n",
       "      <td>3.903530e+06</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFExportsPerCap</td>\n",
       "      <td>1.235702e-03</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.796563e-02</td>\n",
       "      <td>4.320239e-02</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFExportsTotGHA</td>\n",
       "      <td>4.163909e+03</td>\n",
       "      <td>11917.716150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1564.542965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.279316e+05</td>\n",
       "      <td>1.455778e+05</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFImportsPerCap</td>\n",
       "      <td>2.279915e-01</td>\n",
       "      <td>0.065940</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.094818e-02</td>\n",
       "      <td>3.679730e-01</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFImportsTotGHA</td>\n",
       "      <td>7.682560e+05</td>\n",
       "      <td>222194.846200</td>\n",
       "      <td>36.034083</td>\n",
       "      <td>10388.699090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.390719e+05</td>\n",
       "      <td>1.239948e+06</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFProdPerCap</td>\n",
       "      <td>1.598552e-01</td>\n",
       "      <td>0.138346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>5.022942e-01</td>\n",
       "      <td>8.336605e-01</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1993</td>\n",
       "      <td>EFProdTotGHA</td>\n",
       "      <td>5.386591e+05</td>\n",
       "      <td>466181.595600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4034.035036</td>\n",
       "      <td>107720.238800</td>\n",
       "      <td>1.692566e+06</td>\n",
       "      <td>2.809161e+06</td>\n",
       "      <td>886.033</td>\n",
       "      <td>3370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country ISO alpha-3 code UN_region  UN_subregion  year           record  \\\n",
       "0   Armenia              ARM      Asia  Western Asia  1992     BiocapPerCap   \n",
       "1   Armenia              ARM      Asia  Western Asia  1992     BiocapTotGHA   \n",
       "2   Armenia              ARM      Asia  Western Asia  1992     EFConsPerCap   \n",
       "3   Armenia              ARM      Asia  Western Asia  1992     EFConsTotGHA   \n",
       "4   Armenia              ARM      Asia  Western Asia  1992  EFExportsPerCap   \n",
       "5   Armenia              ARM      Asia  Western Asia  1992  EFExportsTotGHA   \n",
       "6   Armenia              ARM      Asia  Western Asia  1992  EFImportsPerCap   \n",
       "7   Armenia              ARM      Asia  Western Asia  1992  EFImportsTotGHA   \n",
       "8   Armenia              ARM      Asia  Western Asia  1992     EFProdPerCap   \n",
       "9   Armenia              ARM      Asia  Western Asia  1992     EFProdTotGHA   \n",
       "10  Armenia              ARM      Asia  Western Asia  1993     BiocapPerCap   \n",
       "11  Armenia              ARM      Asia  Western Asia  1993     BiocapTotGHA   \n",
       "12  Armenia              ARM      Asia  Western Asia  1993     EFConsPerCap   \n",
       "13  Armenia              ARM      Asia  Western Asia  1993     EFConsTotGHA   \n",
       "14  Armenia              ARM      Asia  Western Asia  1993  EFExportsPerCap   \n",
       "15  Armenia              ARM      Asia  Western Asia  1993  EFExportsTotGHA   \n",
       "16  Armenia              ARM      Asia  Western Asia  1993  EFImportsPerCap   \n",
       "17  Armenia              ARM      Asia  Western Asia  1993  EFImportsTotGHA   \n",
       "18  Armenia              ARM      Asia  Western Asia  1993     EFProdPerCap   \n",
       "19  Armenia              ARM      Asia  Western Asia  1993     EFProdTotGHA   \n",
       "\n",
       "       crop_land   grazing_land    forest_land  fishing_ground  built_up_land  \\\n",
       "0   1.611286e-01       0.135023       0.083836        0.013718       0.033669   \n",
       "1   5.558130e+05  465763.337400  289190.662300    47320.224590  116139.598200   \n",
       "2   3.909225e-01       0.189137       0.000001        0.004138       0.033669   \n",
       "3   1.348487e+06  652429.066600       4.327841    14272.803690  116139.598200   \n",
       "4   1.124910e-03       0.002283       0.000000        0.000438       0.000000   \n",
       "5   3.880378e+03    7875.331688       0.000000     1512.195296       0.000000   \n",
       "6   2.309189e-01       0.056397       0.000001        0.003312       0.000000   \n",
       "7   7.965547e+05  194541.060900       4.327841    11426.058040       0.000000   \n",
       "8   1.611286e-01       0.135023       0.000000        0.001264       0.033669   \n",
       "9   5.558130e+05  465763.337400       0.000000     4358.940944  116139.598200   \n",
       "10  1.598552e-01       0.138346       0.085972        0.014035       0.031968   \n",
       "11  5.386591e+05  466181.595600  289695.836700    47293.877270  107720.238800   \n",
       "12  3.866109e-01       0.200749       0.000011        0.003816       0.031968   \n",
       "13  1.302751e+06  676458.725700      36.034083    12858.191160  107720.238800   \n",
       "14  1.235702e-03       0.003537       0.000000        0.000464       0.000000   \n",
       "15  4.163909e+03   11917.716150       0.000000     1564.542965       0.000000   \n",
       "16  2.279915e-01       0.065940       0.000011        0.003083       0.000000   \n",
       "17  7.682560e+05  222194.846200      36.034083    10388.699090       0.000000   \n",
       "18  1.598552e-01       0.138346       0.000000        0.001197       0.031968   \n",
       "19  5.386591e+05  466181.595600       0.000000     4034.035036  107720.238800   \n",
       "\n",
       "          carbon         total  Percapita GDP (2010 USD)  population  \n",
       "0   0.000000e+00  4.273741e-01                   949.033     3449000  \n",
       "1   0.000000e+00  1.474227e+06                   949.033     3449000  \n",
       "2   1.112225e+00  1.730092e+00                   949.033     3449000  \n",
       "3   3.836620e+06  5.967954e+06                   949.033     3449000  \n",
       "4   4.819043e-02  5.203676e-02                   949.033     3449000  \n",
       "5   1.662329e+05  1.795008e+05                   949.033     3449000  \n",
       "6   8.791121e-02  3.785406e-01                   949.033     3449000  \n",
       "7   3.032497e+05  1.305776e+06                   949.033     3449000  \n",
       "8   1.072504e+00  1.403588e+00                   949.033     3449000  \n",
       "9   3.699604e+06  4.841678e+06                   949.033     3449000  \n",
       "10  0.000000e+00  4.301759e-01                   886.033     3370000  \n",
       "11  0.000000e+00  1.449551e+06                   886.033     3370000  \n",
       "12  5.352768e-01  1.158431e+00                   886.033     3370000  \n",
       "13  1.803706e+06  3.903530e+06                   886.033     3370000  \n",
       "14  3.796563e-02  4.320239e-02                   886.033     3370000  \n",
       "15  1.279316e+05  1.455778e+05                   886.033     3370000  \n",
       "16  7.094818e-02  3.679730e-01                   886.033     3370000  \n",
       "17  2.390719e+05  1.239948e+06                   886.033     3370000  \n",
       "18  5.022942e-01  8.336605e-01                   886.033     3370000  \n",
       "19  1.692566e+06  2.809161e+06                   886.033     3370000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"data/NFA_2018.csv\")\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dialogue Model Training\n",
    "\n",
    "Train the RASA dialogue model using your training data and the code from the lab notebook. Feel free to add code/markdown cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NLU Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages (2.0.0)\n",
      "\n",
      "    Linking successful\n",
      "    C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\en_core_web_sm\n",
      "    -->\n",
      "    C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\spacy\\data\\en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NLU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu_data/intents.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 78 (9 distinct intents)\n",
      "\t- Found intents: 'goodbye', 'presence_check', 'affirm', 'results_query', 'deny', 'summary_query', 'inform', 'greet', 'thanks'\n",
      "\t- entity examples: 25 (4 distinct entities)\n",
      "\t- found entities: 'year_range', 'year', 'record', 'country'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_entity_featurizer_regex\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'c:\\mie451\\assignment-cai-nicolwon\\assignment\\models\\nlu\\default\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu_data/intents.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data, verbose=True)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use and Evaluate NLU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu_data/intents.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 78 (9 distinct intents)\n",
      "\t- Found intents: 'goodbye', 'presence_check', 'affirm', 'results_query', 'deny', 'summary_query', 'inform', 'greet', 'thanks'\n",
      "\t- entity examples: 25 (4 distinct entities)\n",
      "\t- found entities: 'year_range', 'year', 'record', 'country'\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Intent evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Intent Evaluation: Only considering those 78 examples that have a defined intent out of 78 examples\n",
      "INFO:rasa_nlu.evaluate:F1-Score:  0.9871794871794872\n",
      "INFO:rasa_nlu.evaluate:Precision: 0.9881656804733728\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  0.9871794871794872\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        affirm       1.00      1.00      1.00         9\n",
      "          deny       1.00      1.00      1.00         9\n",
      "       goodbye       1.00      0.92      0.96        13\n",
      "         greet       0.92      1.00      0.96        12\n",
      "        inform       1.00      1.00      1.00        10\n",
      "presence_check       1.00      1.00      1.00         3\n",
      " results_query       1.00      1.00      1.00         9\n",
      " summary_query       1.00      1.00      1.00         6\n",
      "        thanks       1.00      1.00      1.00         7\n",
      "\n",
      "   avg / total       0.99      0.99      0.99        78\n",
      "\n",
      "INFO:rasa_nlu.evaluate:There were some nlu intent classification errors. Use `--verbose` to show them in the log.\n",
      "INFO:rasa_nlu.evaluate:Model prediction errors saved to errors.json.\n",
      "INFO:rasa_nlu.evaluate:Confusion matrix, without normalization: \n",
      "[[ 9  0  0  0  0  0  0  0  0]\n",
      " [ 0  9  0  0  0  0  0  0  0]\n",
      " [ 0  0 12  1  0  0  0  0  0]\n",
      " [ 0  0  0 12  0  0  0  0  0]\n",
      " [ 0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0]\n",
      " [ 0  0  0  0  0  0  0  0  7]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.evaluate:Entity evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Evaluation for entity extractor: ner_crf \n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    country       1.00      1.00      1.00        19\n",
      "  no_entity       1.00      1.00      1.00       211\n",
      "     record       1.00      1.00      1.00         6\n",
      "       year       1.00      1.00      1.00         6\n",
      " year_range       1.00      1.00      1.00         9\n",
      "\n",
      "avg / total       1.00      1.00      1.00       251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu_data/intents.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apscheduler.scheduler:Scheduler started\n",
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\pykwalify\\core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "WARNING:rasa_core.training.dsl:Found unknown intent 'fallback' on line 15. Please, make sure that all intents are listed in your domain yaml.\n",
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 14/14 [00:00<00:00, 112.90it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|████████████████████████████████████████████| 14/14 [00:00<00:00, 93.96it/s, # trackers=7]\n",
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 14/14 [00:00<00:00, 66.04it/s, # trackers=10]\n",
      "Processed Story Blocks: 100%|████████████████████████████████████████████| 14/14 [00:00<00:00, 71.05it/s, # trackers=8]\n",
      "Processed actions: 788it [00:03, 211.09it/s, # examples=788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 33)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8448      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 8,976\n",
      "Trainable params: 8,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Fitting model with 788 total samples and a validation split of 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "788/788 [==============================] - ETA: 29s - loss: 2.7462 - acc: 0.06 - ETA: 5s - loss: 2.7172 - acc: 0.1437 - ETA: 4s - loss: 2.7055 - acc: 0.182 - ETA: 2s - loss: 2.6555 - acc: 0.281 - ETA: 1s - loss: 2.6223 - acc: 0.336 - ETA: 0s - loss: 2.5811 - acc: 0.373 - ETA: 0s - loss: 2.5352 - acc: 0.387 - ETA: 0s - loss: 2.5286 - acc: 0.387 - 2s 2ms/step - loss: 2.5205 - acc: 0.3883\n",
      "Epoch 2/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 2.2022 - acc: 0.531 - ETA: 0s - loss: 2.2738 - acc: 0.437 - ETA: 0s - loss: 2.2707 - acc: 0.425 - ETA: 0s - loss: 2.2612 - acc: 0.420 - ETA: 0s - loss: 2.2295 - acc: 0.432 - ETA: 0s - loss: 2.1944 - acc: 0.439 - ETA: 0s - loss: 2.1616 - acc: 0.443 - ETA: 0s - loss: 2.1471 - acc: 0.447 - 0s 538us/step - loss: 2.1269 - acc: 0.4518\n",
      "Epoch 3/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 2.0251 - acc: 0.500 - ETA: 0s - loss: 2.0674 - acc: 0.445 - ETA: 0s - loss: 2.0399 - acc: 0.450 - ETA: 0s - loss: 2.1135 - acc: 0.415 - ETA: 0s - loss: 2.0744 - acc: 0.418 - ETA: 0s - loss: 2.0316 - acc: 0.435 - ETA: 0s - loss: 2.0214 - acc: 0.441 - 0s 514us/step - loss: 1.9934 - acc: 0.4518\n",
      "Epoch 4/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.8451 - acc: 0.437 - ETA: 0s - loss: 1.9472 - acc: 0.432 - ETA: 0s - loss: 1.9775 - acc: 0.423 - ETA: 0s - loss: 1.9345 - acc: 0.439 - ETA: 0s - loss: 1.9461 - acc: 0.435 - ETA: 0s - loss: 1.9468 - acc: 0.432 - ETA: 0s - loss: 1.9261 - acc: 0.444 - 0s 527us/step - loss: 1.9039 - acc: 0.4518\n",
      "Epoch 5/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.7396 - acc: 0.500 - ETA: 0s - loss: 1.9150 - acc: 0.442 - ETA: 0s - loss: 1.9127 - acc: 0.437 - ETA: 0s - loss: 1.9069 - acc: 0.434 - ETA: 0s - loss: 1.8567 - acc: 0.450 - ETA: 0s - loss: 1.8306 - acc: 0.461 - 0s 428us/step - loss: 1.8494 - acc: 0.4518\n",
      "Epoch 6/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.4721 - acc: 0.656 - ETA: 0s - loss: 1.7198 - acc: 0.505 - ETA: 0s - loss: 1.7552 - acc: 0.485 - ETA: 0s - loss: 1.7871 - acc: 0.456 - ETA: 0s - loss: 1.7845 - acc: 0.455 - ETA: 0s - loss: 1.7820 - acc: 0.458 - 0s 434us/step - loss: 1.7894 - acc: 0.4518\n",
      "Epoch 7/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.8348 - acc: 0.406 - ETA: 0s - loss: 1.6589 - acc: 0.500 - ETA: 0s - loss: 1.6887 - acc: 0.479 - ETA: 0s - loss: 1.6718 - acc: 0.480 - ETA: 0s - loss: 1.7030 - acc: 0.460 - ETA: 0s - loss: 1.7059 - acc: 0.457 - ETA: 0s - loss: 1.7099 - acc: 0.457 - 0s 478us/step - loss: 1.7227 - acc: 0.4518\n",
      "Epoch 8/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.8822 - acc: 0.375 - ETA: 0s - loss: 1.7629 - acc: 0.401 - ETA: 0s - loss: 1.7384 - acc: 0.400 - ETA: 0s - loss: 1.6910 - acc: 0.437 - ETA: 0s - loss: 1.6542 - acc: 0.452 - ETA: 0s - loss: 1.6691 - acc: 0.447 - 0s 416us/step - loss: 1.6589 - acc: 0.4530\n",
      "Epoch 9/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.1931 - acc: 0.625 - ETA: 0s - loss: 1.5418 - acc: 0.487 - ETA: 0s - loss: 1.6243 - acc: 0.463 - ETA: 0s - loss: 1.6322 - acc: 0.455 - ETA: 0s - loss: 1.6313 - acc: 0.449 - ETA: 0s - loss: 1.6109 - acc: 0.454 - ETA: 0s - loss: 1.6028 - acc: 0.460 - 0s 560us/step - loss: 1.6024 - acc: 0.4607\n",
      "Epoch 10/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.4460 - acc: 0.531 - ETA: 0s - loss: 1.4283 - acc: 0.520 - ETA: 0s - loss: 1.4545 - acc: 0.506 - ETA: 0s - loss: 1.4827 - acc: 0.490 - ETA: 0s - loss: 1.5047 - acc: 0.477 - ETA: 0s - loss: 1.5185 - acc: 0.473 - 0s 447us/step - loss: 1.5324 - acc: 0.4657\n",
      "Epoch 11/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.9058 - acc: 0.218 - ETA: 0s - loss: 1.5931 - acc: 0.429 - ETA: 0s - loss: 1.5340 - acc: 0.450 - ETA: 0s - loss: 1.4817 - acc: 0.460 - ETA: 0s - loss: 1.4474 - acc: 0.483 - ETA: 0s - loss: 1.4597 - acc: 0.475 - ETA: 0s - loss: 1.4627 - acc: 0.477 - ETA: 0s - loss: 1.4622 - acc: 0.477 - ETA: 0s - loss: 1.4586 - acc: 0.476 - 1s 657us/step - loss: 1.4726 - acc: 0.4695\n",
      "Epoch 12/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.4541 - acc: 0.437 - ETA: 0s - loss: 1.4509 - acc: 0.487 - ETA: 0s - loss: 1.4179 - acc: 0.500 - ETA: 0s - loss: 1.4409 - acc: 0.476 - ETA: 0s - loss: 1.4041 - acc: 0.491 - ETA: 0s - loss: 1.3797 - acc: 0.500 - 0s 416us/step - loss: 1.4011 - acc: 0.4860\n",
      "Epoch 13/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.3709 - acc: 0.500 - ETA: 0s - loss: 1.4590 - acc: 0.484 - ETA: 0s - loss: 1.3129 - acc: 0.537 - ETA: 0s - loss: 1.2938 - acc: 0.535 - ETA: 0s - loss: 1.3321 - acc: 0.517 - ETA: 0s - loss: 1.3459 - acc: 0.507 - ETA: 0s - loss: 1.3472 - acc: 0.509 - ETA: 0s - loss: 1.3290 - acc: 0.520 - 0s 549us/step - loss: 1.3316 - acc: 0.5190\n",
      "Epoch 14/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.1801 - acc: 0.593 - ETA: 0s - loss: 1.2794 - acc: 0.541 - ETA: 0s - loss: 1.2406 - acc: 0.556 - ETA: 0s - loss: 1.2556 - acc: 0.546 - ETA: 0s - loss: 1.2387 - acc: 0.554 - ETA: 0s - loss: 1.2423 - acc: 0.552 - ETA: 0s - loss: 1.2333 - acc: 0.555 - 0s 462us/step - loss: 1.2396 - acc: 0.5546\n",
      "Epoch 15/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.1538 - acc: 0.593 - ETA: 0s - loss: 1.0980 - acc: 0.625 - ETA: 0s - loss: 1.0955 - acc: 0.635 - ETA: 0s - loss: 1.1361 - acc: 0.622 - ETA: 0s - loss: 1.1446 - acc: 0.618 - ETA: 0s - loss: 1.1442 - acc: 0.619 - 0s 401us/step - loss: 1.1524 - acc: 0.6180\n",
      "Epoch 16/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.0564 - acc: 0.687 - ETA: 0s - loss: 1.0827 - acc: 0.661 - ETA: 0s - loss: 1.0744 - acc: 0.665 - ETA: 0s - loss: 1.0775 - acc: 0.667 - ETA: 0s - loss: 1.0879 - acc: 0.654 - ETA: 0s - loss: 1.0851 - acc: 0.657 - ETA: 0s - loss: 1.0714 - acc: 0.667 - 0s 452us/step - loss: 1.0688 - acc: 0.6701\n",
      "Epoch 17/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.9958 - acc: 0.750 - ETA: 0s - loss: 1.0478 - acc: 0.708 - ETA: 0s - loss: 1.0699 - acc: 0.696 - ETA: 0s - loss: 1.0546 - acc: 0.707 - ETA: 0s - loss: 1.0125 - acc: 0.715 - 0s 363us/step - loss: 0.9979 - acc: 0.7183\n",
      "Epoch 18/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.8913 - acc: 0.750 - ETA: 0s - loss: 0.9442 - acc: 0.739 - ETA: 0s - loss: 1.0081 - acc: 0.727 - ETA: 0s - loss: 0.9786 - acc: 0.736 - ETA: 0s - loss: 0.9261 - acc: 0.750 - 0s 357us/step - loss: 0.9154 - acc: 0.7538\n",
      "Epoch 19/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.0365 - acc: 0.812 - ETA: 0s - loss: 0.9001 - acc: 0.800 - ETA: 0s - loss: 0.8509 - acc: 0.798 - ETA: 0s - loss: 0.8411 - acc: 0.793 - ETA: 0s - loss: 0.8380 - acc: 0.803 - ETA: 0s - loss: 0.8344 - acc: 0.804 - 0s 415us/step - loss: 0.8460 - acc: 0.7906\n",
      "Epoch 20/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 1.0777 - acc: 0.687 - ETA: 0s - loss: 0.9232 - acc: 0.762 - ETA: 0s - loss: 0.8617 - acc: 0.777 - ETA: 0s - loss: 0.8270 - acc: 0.785 - ETA: 0s - loss: 0.8012 - acc: 0.794 - ETA: 0s - loss: 0.7872 - acc: 0.803 - 0s 398us/step - loss: 0.7954 - acc: 0.7995\n",
      "Epoch 21/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6091 - acc: 0.937 - ETA: 0s - loss: 0.7315 - acc: 0.849 - ETA: 0s - loss: 0.7972 - acc: 0.803 - ETA: 0s - loss: 0.7994 - acc: 0.800 - ETA: 0s - loss: 0.7718 - acc: 0.812 - ETA: 0s - loss: 0.7381 - acc: 0.822 - 0s 410us/step - loss: 0.7350 - acc: 0.8236\n",
      "Epoch 22/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6694 - acc: 0.843 - ETA: 0s - loss: 0.7024 - acc: 0.837 - ETA: 0s - loss: 0.7221 - acc: 0.809 - ETA: 0s - loss: 0.6936 - acc: 0.832 - ETA: 0s - loss: 0.6961 - acc: 0.835 - ETA: 0s - loss: 0.6859 - acc: 0.846 - 0s 392us/step - loss: 0.6879 - acc: 0.8439\n",
      "Epoch 23/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.5981 - acc: 0.812 - ETA: 0s - loss: 0.6595 - acc: 0.833 - ETA: 0s - loss: 0.6341 - acc: 0.833 - ETA: 0s - loss: 0.6284 - acc: 0.851 - ETA: 0s - loss: 0.6466 - acc: 0.840 - ETA: 0s - loss: 0.6287 - acc: 0.853 - 0s 425us/step - loss: 0.6387 - acc: 0.8579\n",
      "Epoch 24/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.4274 - acc: 0.968 - ETA: 0s - loss: 0.5646 - acc: 0.916 - ETA: 0s - loss: 0.6260 - acc: 0.892 - ETA: 0s - loss: 0.6322 - acc: 0.879 - ETA: 0s - loss: 0.6134 - acc: 0.883 - ETA: 0s - loss: 0.6039 - acc: 0.886 - 0s 448us/step - loss: 0.6021 - acc: 0.8858\n",
      "Epoch 25/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6346 - acc: 0.875 - ETA: 0s - loss: 0.5408 - acc: 0.906 - ETA: 0s - loss: 0.5444 - acc: 0.896 - ETA: 0s - loss: 0.5419 - acc: 0.892 - ETA: 0s - loss: 0.5397 - acc: 0.890 - ETA: 0s - loss: 0.5493 - acc: 0.885 - ETA: 0s - loss: 0.5545 - acc: 0.885 - 0s 459us/step - loss: 0.5562 - acc: 0.8858\n",
      "Epoch 26/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6734 - acc: 0.781 - ETA: 0s - loss: 0.5189 - acc: 0.912 - ETA: 0s - loss: 0.5449 - acc: 0.896 - ETA: 0s - loss: 0.5583 - acc: 0.882 - ETA: 0s - loss: 0.5300 - acc: 0.890 - ETA: 0s - loss: 0.5388 - acc: 0.884 - 0s 435us/step - loss: 0.5395 - acc: 0.8858\n",
      "Epoch 27/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6423 - acc: 0.812 - ETA: 0s - loss: 0.4942 - acc: 0.890 - ETA: 0s - loss: 0.5257 - acc: 0.875 - ETA: 0s - loss: 0.5463 - acc: 0.877 - ETA: 0s - loss: 0.5219 - acc: 0.878 - ETA: 0s - loss: 0.5061 - acc: 0.886 - ETA: 0s - loss: 0.5039 - acc: 0.887 - 0s 486us/step - loss: 0.5010 - acc: 0.8896\n",
      "Epoch 28/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.4169 - acc: 0.968 - ETA: 0s - loss: 0.4677 - acc: 0.900 - ETA: 0s - loss: 0.4380 - acc: 0.913 - ETA: 0s - loss: 0.4386 - acc: 0.913 - ETA: 0s - loss: 0.4582 - acc: 0.914 - ETA: 0s - loss: 0.4784 - acc: 0.907 - ETA: 0s - loss: 0.4640 - acc: 0.909 - 0s 489us/step - loss: 0.4619 - acc: 0.9099\n",
      "Epoch 29/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.6871 - acc: 0.781 - ETA: 0s - loss: 0.4239 - acc: 0.927 - ETA: 0s - loss: 0.4301 - acc: 0.921 - ETA: 0s - loss: 0.4444 - acc: 0.915 - ETA: 0s - loss: 0.4448 - acc: 0.916 - ETA: 0s - loss: 0.4412 - acc: 0.915 - 0s 423us/step - loss: 0.4413 - acc: 0.9162\n",
      "Epoch 30/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.4588 - acc: 0.937 - ETA: 0s - loss: 0.4489 - acc: 0.910 - ETA: 0s - loss: 0.4515 - acc: 0.909 - ETA: 0s - loss: 0.4219 - acc: 0.919 - ETA: 0s - loss: 0.4197 - acc: 0.913 - ETA: 0s - loss: 0.4172 - acc: 0.913 - 0s 426us/step - loss: 0.4150 - acc: 0.9137\n",
      "Epoch 31/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.3885 - acc: 0.937 - ETA: 0s - loss: 0.3653 - acc: 0.932 - ETA: 0s - loss: 0.3834 - acc: 0.917 - ETA: 0s - loss: 0.3976 - acc: 0.920 - ETA: 0s - loss: 0.3981 - acc: 0.916 - ETA: 0s - loss: 0.3874 - acc: 0.920 - 0s 411us/step - loss: 0.3994 - acc: 0.9150\n",
      "Epoch 32/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.3793 - acc: 0.937 - ETA: 0s - loss: 0.3895 - acc: 0.937 - ETA: 0s - loss: 0.3681 - acc: 0.934 - ETA: 0s - loss: 0.3600 - acc: 0.937 - ETA: 0s - loss: 0.3526 - acc: 0.941 - ETA: 0s - loss: 0.3539 - acc: 0.942 - 0s 415us/step - loss: 0.3661 - acc: 0.9378\n",
      "Epoch 33/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.3761 - acc: 0.968 - ETA: 0s - loss: 0.3742 - acc: 0.937 - ETA: 0s - loss: 0.3432 - acc: 0.944 - ETA: 0s - loss: 0.3377 - acc: 0.940 - ETA: 0s - loss: 0.3477 - acc: 0.933 - ETA: 0s - loss: 0.3394 - acc: 0.937 - ETA: 0s - loss: 0.3434 - acc: 0.941 - 0s 482us/step - loss: 0.3361 - acc: 0.9416\n",
      "Epoch 34/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.3097 - acc: 0.906 - ETA: 0s - loss: 0.3492 - acc: 0.927 - ETA: 0s - loss: 0.3387 - acc: 0.934 - ETA: 0s - loss: 0.3077 - acc: 0.939 - ETA: 0s - loss: 0.3083 - acc: 0.939 - ETA: 0s - loss: 0.3112 - acc: 0.936 - 0s 425us/step - loss: 0.3202 - acc: 0.9340\n",
      "Epoch 35/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2688 - acc: 0.968 - ETA: 0s - loss: 0.3122 - acc: 0.925 - ETA: 0s - loss: 0.3215 - acc: 0.918 - ETA: 0s - loss: 0.3321 - acc: 0.924 - ETA: 0s - loss: 0.3252 - acc: 0.935 - ETA: 0s - loss: 0.3163 - acc: 0.938 - 0s 425us/step - loss: 0.3120 - acc: 0.9391\n",
      "Epoch 36/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2741 - acc: 0.968 - ETA: 0s - loss: 0.3402 - acc: 0.933 - ETA: 0s - loss: 0.3365 - acc: 0.937 - ETA: 0s - loss: 0.3357 - acc: 0.931 - ETA: 0s - loss: 0.3188 - acc: 0.935 - ETA: 0s - loss: 0.3076 - acc: 0.934 - 0s 409us/step - loss: 0.3145 - acc: 0.9315\n",
      "Epoch 37/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2994 - acc: 0.968 - ETA: 0s - loss: 0.2326 - acc: 0.974 - ETA: 0s - loss: 0.2410 - acc: 0.968 - ETA: 0s - loss: 0.2613 - acc: 0.959 - ETA: 0s - loss: 0.2678 - acc: 0.955 - 0s 354us/step - loss: 0.2705 - acc: 0.9492\n",
      "Epoch 38/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2741 - acc: 0.937 - ETA: 0s - loss: 0.2894 - acc: 0.932 - ETA: 0s - loss: 0.2817 - acc: 0.931 - ETA: 0s - loss: 0.2927 - acc: 0.937 - ETA: 0s - loss: 0.2822 - acc: 0.939 - 0s 359us/step - loss: 0.2735 - acc: 0.9454\n",
      "Epoch 39/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1590 - acc: 1.000 - ETA: 0s - loss: 0.2435 - acc: 0.943 - ETA: 0s - loss: 0.2697 - acc: 0.934 - ETA: 0s - loss: 0.2586 - acc: 0.943 - ETA: 0s - loss: 0.2539 - acc: 0.946 - ETA: 0s - loss: 0.2544 - acc: 0.946 - 0s 379us/step - loss: 0.2527 - acc: 0.9480\n",
      "Epoch 40/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1277 - acc: 1.000 - ETA: 0s - loss: 0.2452 - acc: 0.953 - ETA: 0s - loss: 0.2349 - acc: 0.954 - ETA: 0s - loss: 0.2443 - acc: 0.954 - ETA: 0s - loss: 0.2418 - acc: 0.957 - 0s 357us/step - loss: 0.2425 - acc: 0.9581\n",
      "Epoch 41/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2709 - acc: 0.906 - ETA: 0s - loss: 0.2264 - acc: 0.968 - ETA: 0s - loss: 0.2343 - acc: 0.968 - ETA: 0s - loss: 0.2410 - acc: 0.960 - ETA: 0s - loss: 0.2427 - acc: 0.960 - ETA: 0s - loss: 0.2406 - acc: 0.960 - 0s 397us/step - loss: 0.2367 - acc: 0.9581\n",
      "Epoch 42/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1702 - acc: 0.968 - ETA: 0s - loss: 0.2110 - acc: 0.953 - ETA: 0s - loss: 0.2320 - acc: 0.951 - ETA: 0s - loss: 0.2233 - acc: 0.955 - ETA: 0s - loss: 0.2211 - acc: 0.957 - ETA: 0s - loss: 0.2192 - acc: 0.958 - 0s 393us/step - loss: 0.2194 - acc: 0.9569\n",
      "Epoch 43/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.3030 - acc: 0.906 - ETA: 0s - loss: 0.2379 - acc: 0.937 - ETA: 0s - loss: 0.2328 - acc: 0.954 - ETA: 0s - loss: 0.2167 - acc: 0.957 - ETA: 0s - loss: 0.2261 - acc: 0.950 - ETA: 0s - loss: 0.2332 - acc: 0.947 - 0s 419us/step - loss: 0.2345 - acc: 0.9480\n",
      "Epoch 44/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2452 - acc: 0.937 - ETA: 0s - loss: 0.2232 - acc: 0.953 - ETA: 0s - loss: 0.2241 - acc: 0.946 - ETA: 0s - loss: 0.2258 - acc: 0.945 - ETA: 0s - loss: 0.2182 - acc: 0.950 - ETA: 0s - loss: 0.2195 - acc: 0.951 - ETA: 0s - loss: 0.2276 - acc: 0.949 - 0s 510us/step - loss: 0.2257 - acc: 0.9492\n",
      "Epoch 45/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1636 - acc: 0.968 - ETA: 0s - loss: 0.2587 - acc: 0.950 - ETA: 0s - loss: 0.2347 - acc: 0.951 - ETA: 0s - loss: 0.2195 - acc: 0.955 - ETA: 0s - loss: 0.2335 - acc: 0.951 - ETA: 0s - loss: 0.2336 - acc: 0.946 - ETA: 0s - loss: 0.2293 - acc: 0.947 - 0s 491us/step - loss: 0.2290 - acc: 0.9480\n",
      "Epoch 46/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1172 - acc: 0.968 - ETA: 0s - loss: 0.2048 - acc: 0.962 - ETA: 0s - loss: 0.1805 - acc: 0.965 - ETA: 0s - loss: 0.1777 - acc: 0.973 - ETA: 0s - loss: 0.1850 - acc: 0.966 - ETA: 0s - loss: 0.1912 - acc: 0.965 - ETA: 0s - loss: 0.1937 - acc: 0.963 - 0s 495us/step - loss: 0.2032 - acc: 0.9607\n",
      "Epoch 47/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2171 - acc: 0.968 - ETA: 0s - loss: 0.2301 - acc: 0.956 - ETA: 0s - loss: 0.2067 - acc: 0.962 - ETA: 0s - loss: 0.2014 - acc: 0.954 - ETA: 0s - loss: 0.1963 - acc: 0.959 - ETA: 0s - loss: 0.1914 - acc: 0.958 - 0s 420us/step - loss: 0.1942 - acc: 0.9581\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788/788 [==============================] - ETA: 0s - loss: 0.4507 - acc: 0.937 - ETA: 0s - loss: 0.2367 - acc: 0.960 - ETA: 0s - loss: 0.1839 - acc: 0.972 - ETA: 0s - loss: 0.1728 - acc: 0.975 - ETA: 0s - loss: 0.1986 - acc: 0.966 - ETA: 0s - loss: 0.1990 - acc: 0.961 - ETA: 0s - loss: 0.2017 - acc: 0.957 - 0s 490us/step - loss: 0.1974 - acc: 0.9581\n",
      "Epoch 49/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1029 - acc: 1.000 - ETA: 0s - loss: 0.1639 - acc: 0.958 - ETA: 0s - loss: 0.1648 - acc: 0.959 - ETA: 0s - loss: 0.1892 - acc: 0.952 - ETA: 0s - loss: 0.1974 - acc: 0.950 - 0s 357us/step - loss: 0.1911 - acc: 0.9556\n",
      "Epoch 50/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0956 - acc: 1.000 - ETA: 0s - loss: 0.1748 - acc: 0.963 - ETA: 0s - loss: 0.1475 - acc: 0.965 - ETA: 0s - loss: 0.1578 - acc: 0.966 - ETA: 0s - loss: 0.1545 - acc: 0.965 - 0s 359us/step - loss: 0.1618 - acc: 0.9645\n",
      "Epoch 51/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2642 - acc: 0.937 - ETA: 0s - loss: 0.1960 - acc: 0.962 - ETA: 0s - loss: 0.2028 - acc: 0.960 - ETA: 0s - loss: 0.2035 - acc: 0.955 - ETA: 0s - loss: 0.2001 - acc: 0.957 - ETA: 0s - loss: 0.1993 - acc: 0.962 - 0s 422us/step - loss: 0.1949 - acc: 0.9632\n",
      "Epoch 52/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1900 - acc: 0.937 - ETA: 0s - loss: 0.2722 - acc: 0.911 - ETA: 0s - loss: 0.2228 - acc: 0.932 - ETA: 0s - loss: 0.2064 - acc: 0.939 - ETA: 0s - loss: 0.1933 - acc: 0.948 - ETA: 0s - loss: 0.1869 - acc: 0.951 - 0s 435us/step - loss: 0.1826 - acc: 0.9543\n",
      "Epoch 53/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2604 - acc: 0.937 - ETA: 0s - loss: 0.2215 - acc: 0.950 - ETA: 0s - loss: 0.2138 - acc: 0.940 - ETA: 0s - loss: 0.2077 - acc: 0.947 - ETA: 0s - loss: 0.1925 - acc: 0.953 - ETA: 0s - loss: 0.1759 - acc: 0.957 - ETA: 0s - loss: 0.1786 - acc: 0.954 - 0s 475us/step - loss: 0.1766 - acc: 0.9543\n",
      "Epoch 54/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2085 - acc: 0.968 - ETA: 0s - loss: 0.1325 - acc: 0.981 - ETA: 0s - loss: 0.1535 - acc: 0.968 - ETA: 0s - loss: 0.1492 - acc: 0.968 - ETA: 0s - loss: 0.1714 - acc: 0.959 - ETA: 0s - loss: 0.1709 - acc: 0.962 - ETA: 0s - loss: 0.1673 - acc: 0.964 - 0s 481us/step - loss: 0.1690 - acc: 0.9607\n",
      "Epoch 55/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2260 - acc: 0.937 - ETA: 0s - loss: 0.2061 - acc: 0.937 - ETA: 0s - loss: 0.1653 - acc: 0.956 - ETA: 0s - loss: 0.1614 - acc: 0.961 - ETA: 0s - loss: 0.1617 - acc: 0.957 - ETA: 0s - loss: 0.1637 - acc: 0.955 - ETA: 0s - loss: 0.1626 - acc: 0.953 - 0s 456us/step - loss: 0.1705 - acc: 0.9492\n",
      "Epoch 56/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1428 - acc: 0.937 - ETA: 0s - loss: 0.1733 - acc: 0.958 - ETA: 0s - loss: 0.1701 - acc: 0.950 - ETA: 0s - loss: 0.1611 - acc: 0.956 - ETA: 0s - loss: 0.1531 - acc: 0.957 - ETA: 0s - loss: 0.1583 - acc: 0.953 - 0s 463us/step - loss: 0.1600 - acc: 0.9569\n",
      "Epoch 57/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0680 - acc: 0.968 - ETA: 0s - loss: 0.1467 - acc: 0.974 - ETA: 0s - loss: 0.1554 - acc: 0.965 - ETA: 0s - loss: 0.1518 - acc: 0.968 - ETA: 0s - loss: 0.1570 - acc: 0.964 - ETA: 0s - loss: 0.1563 - acc: 0.967 - ETA: 0s - loss: 0.1547 - acc: 0.970 - 0s 464us/step - loss: 0.1518 - acc: 0.9708\n",
      "Epoch 58/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1508 - acc: 0.968 - ETA: 0s - loss: 0.1488 - acc: 0.958 - ETA: 0s - loss: 0.1611 - acc: 0.949 - ETA: 0s - loss: 0.1617 - acc: 0.953 - ETA: 0s - loss: 0.1483 - acc: 0.958 - ETA: 0s - loss: 0.1493 - acc: 0.957 - ETA: 0s - loss: 0.1541 - acc: 0.957 - 0s 457us/step - loss: 0.1557 - acc: 0.9569\n",
      "Epoch 59/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1374 - acc: 0.937 - ETA: 0s - loss: 0.1613 - acc: 0.942 - ETA: 0s - loss: 0.1531 - acc: 0.960 - ETA: 0s - loss: 0.1445 - acc: 0.962 - ETA: 0s - loss: 0.1377 - acc: 0.965 - ETA: 0s - loss: 0.1462 - acc: 0.964 - 0s 400us/step - loss: 0.1440 - acc: 0.9657\n",
      "Epoch 60/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0805 - acc: 1.000 - ETA: 0s - loss: 0.1189 - acc: 0.984 - ETA: 0s - loss: 0.1252 - acc: 0.964 - ETA: 0s - loss: 0.1259 - acc: 0.968 - ETA: 0s - loss: 0.1449 - acc: 0.963 - ETA: 0s - loss: 0.1508 - acc: 0.963 - 0s 438us/step - loss: 0.1513 - acc: 0.9619\n",
      "Epoch 61/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1071 - acc: 0.968 - ETA: 0s - loss: 0.1572 - acc: 0.958 - ETA: 0s - loss: 0.1594 - acc: 0.954 - ETA: 0s - loss: 0.1613 - acc: 0.956 - ETA: 0s - loss: 0.1545 - acc: 0.958 - ETA: 0s - loss: 0.1492 - acc: 0.959 - 0s 385us/step - loss: 0.1531 - acc: 0.9581\n",
      "Epoch 62/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1697 - acc: 0.968 - ETA: 0s - loss: 0.1346 - acc: 0.968 - ETA: 0s - loss: 0.1243 - acc: 0.965 - ETA: 0s - loss: 0.1575 - acc: 0.956 - ETA: 0s - loss: 0.1535 - acc: 0.960 - ETA: 0s - loss: 0.1394 - acc: 0.965 - ETA: 0s - loss: 0.1492 - acc: 0.966 - 0s 504us/step - loss: 0.1458 - acc: 0.9670\n",
      "Epoch 63/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.968 - ETA: 0s - loss: 0.1185 - acc: 0.974 - ETA: 0s - loss: 0.1230 - acc: 0.965 - ETA: 0s - loss: 0.1258 - acc: 0.968 - ETA: 0s - loss: 0.1175 - acc: 0.972 - ETA: 0s - loss: 0.1162 - acc: 0.973 - 0s 420us/step - loss: 0.1178 - acc: 0.9721\n",
      "Epoch 64/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0890 - acc: 1.000 - ETA: 0s - loss: 0.1253 - acc: 0.968 - ETA: 0s - loss: 0.1220 - acc: 0.973 - ETA: 0s - loss: 0.1162 - acc: 0.968 - ETA: 0s - loss: 0.1334 - acc: 0.963 - ETA: 0s - loss: 0.1231 - acc: 0.970 - ETA: 0s - loss: 0.1320 - acc: 0.964 - ETA: 0s - loss: 0.1233 - acc: 0.967 - 0s 528us/step - loss: 0.1230 - acc: 0.9683\n",
      "Epoch 65/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.937 - ETA: 0s - loss: 0.1019 - acc: 0.979 - ETA: 0s - loss: 0.1302 - acc: 0.971 - ETA: 0s - loss: 0.1347 - acc: 0.968 - ETA: 0s - loss: 0.1218 - acc: 0.972 - ETA: 0s - loss: 0.1274 - acc: 0.971 - 0s 437us/step - loss: 0.1325 - acc: 0.9721\n",
      "Epoch 66/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2456 - acc: 0.968 - ETA: 0s - loss: 0.1416 - acc: 0.979 - ETA: 0s - loss: 0.1458 - acc: 0.971 - ETA: 0s - loss: 0.1489 - acc: 0.964 - ETA: 0s - loss: 0.1464 - acc: 0.965 - ETA: 0s - loss: 0.1460 - acc: 0.963 - 0s 421us/step - loss: 0.1416 - acc: 0.9645\n",
      "Epoch 67/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1024 - acc: 1.000 - ETA: 0s - loss: 0.1425 - acc: 0.968 - ETA: 0s - loss: 0.1236 - acc: 0.968 - ETA: 0s - loss: 0.1227 - acc: 0.970 - ETA: 0s - loss: 0.1147 - acc: 0.972 - ETA: 0s - loss: 0.1182 - acc: 0.971 - ETA: 0s - loss: 0.1243 - acc: 0.968 - 0s 472us/step - loss: 0.1294 - acc: 0.9657\n",
      "Epoch 68/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1035 - acc: 0.968 - ETA: 0s - loss: 0.0709 - acc: 0.979 - ETA: 0s - loss: 0.0838 - acc: 0.968 - ETA: 0s - loss: 0.0832 - acc: 0.972 - ETA: 0s - loss: 0.0804 - acc: 0.974 - ETA: 0s - loss: 0.1020 - acc: 0.970 - ETA: 0s - loss: 0.1089 - acc: 0.970 - ETA: 0s - loss: 0.1077 - acc: 0.973 - ETA: 0s - loss: 0.1095 - acc: 0.970 - 1s 666us/step - loss: 0.1136 - acc: 0.9695\n",
      "Epoch 69/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1465 - acc: 0.968 - ETA: 0s - loss: 0.1692 - acc: 0.953 - ETA: 0s - loss: 0.1670 - acc: 0.951 - ETA: 0s - loss: 0.1491 - acc: 0.955 - ETA: 0s - loss: 0.1566 - acc: 0.955 - ETA: 0s - loss: 0.1550 - acc: 0.955 - 0s 453us/step - loss: 0.1530 - acc: 0.9543\n",
      "Epoch 70/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.968 - ETA: 0s - loss: 0.1025 - acc: 0.979 - ETA: 0s - loss: 0.1100 - acc: 0.971 - ETA: 0s - loss: 0.1090 - acc: 0.970 - ETA: 0s - loss: 0.1174 - acc: 0.970 - 0s 357us/step - loss: 0.1126 - acc: 0.9746\n",
      "Epoch 71/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1113 - acc: 0.968 - ETA: 0s - loss: 0.1482 - acc: 0.943 - ETA: 0s - loss: 0.1178 - acc: 0.965 - ETA: 0s - loss: 0.1184 - acc: 0.968 - ETA: 0s - loss: 0.1065 - acc: 0.975 - ETA: 0s - loss: 0.1174 - acc: 0.971 - 0s 388us/step - loss: 0.1152 - acc: 0.9721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0499 - acc: 1.000 - ETA: 0s - loss: 0.1329 - acc: 0.958 - ETA: 0s - loss: 0.1379 - acc: 0.954 - ETA: 0s - loss: 0.1277 - acc: 0.957 - ETA: 0s - loss: 0.1336 - acc: 0.958 - 0s 346us/step - loss: 0.1290 - acc: 0.9607\n",
      "Epoch 73/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0615 - acc: 1.000 - ETA: 0s - loss: 0.1163 - acc: 0.959 - ETA: 0s - loss: 0.1092 - acc: 0.971 - ETA: 0s - loss: 0.1086 - acc: 0.972 - ETA: 0s - loss: 0.1070 - acc: 0.974 - 0s 345us/step - loss: 0.1109 - acc: 0.9721\n",
      "Epoch 74/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0749 - acc: 1.000 - ETA: 0s - loss: 0.0750 - acc: 0.993 - ETA: 0s - loss: 0.0831 - acc: 0.988 - ETA: 0s - loss: 0.0973 - acc: 0.981 - ETA: 0s - loss: 0.1048 - acc: 0.974 - ETA: 0s - loss: 0.1234 - acc: 0.962 - ETA: 0s - loss: 0.1236 - acc: 0.961 - ETA: 0s - loss: 0.1180 - acc: 0.964 - 0s 581us/step - loss: 0.1165 - acc: 0.9645\n",
      "Epoch 75/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2026 - acc: 0.937 - ETA: 0s - loss: 0.1089 - acc: 0.968 - ETA: 0s - loss: 0.1220 - acc: 0.968 - ETA: 0s - loss: 0.1162 - acc: 0.974 - ETA: 0s - loss: 0.1171 - acc: 0.973 - ETA: 0s - loss: 0.1156 - acc: 0.974 - ETA: 0s - loss: 0.1082 - acc: 0.975 - 0s 500us/step - loss: 0.1095 - acc: 0.9784\n",
      "Epoch 76/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0730 - acc: 0.968 - ETA: 0s - loss: 0.0824 - acc: 0.976 - ETA: 0s - loss: 0.1262 - acc: 0.961 - ETA: 0s - loss: 0.1182 - acc: 0.963 - ETA: 0s - loss: 0.1184 - acc: 0.962 - ETA: 0s - loss: 0.1412 - acc: 0.954 - ETA: 0s - loss: 0.1383 - acc: 0.955 - ETA: 0s - loss: 0.1347 - acc: 0.957 - 0s 524us/step - loss: 0.1331 - acc: 0.9581\n",
      "Epoch 77/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.968 - ETA: 0s - loss: 0.1318 - acc: 0.955 - ETA: 0s - loss: 0.1326 - acc: 0.954 - ETA: 0s - loss: 0.1159 - acc: 0.966 - ETA: 0s - loss: 0.1185 - acc: 0.965 - ETA: 0s - loss: 0.1278 - acc: 0.962 - 0s 404us/step - loss: 0.1249 - acc: 0.9632\n",
      "Epoch 78/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1170 - acc: 0.968 - ETA: 0s - loss: 0.1254 - acc: 0.950 - ETA: 0s - loss: 0.1262 - acc: 0.956 - ETA: 0s - loss: 0.1226 - acc: 0.960 - ETA: 0s - loss: 0.1114 - acc: 0.968 - 0s 355us/step - loss: 0.1195 - acc: 0.9670\n",
      "Epoch 79/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0455 - acc: 1.000 - ETA: 0s - loss: 0.0944 - acc: 0.975 - ETA: 0s - loss: 0.1099 - acc: 0.976 - ETA: 0s - loss: 0.1101 - acc: 0.980 - ETA: 0s - loss: 0.1179 - acc: 0.976 - ETA: 0s - loss: 0.1137 - acc: 0.977 - ETA: 0s - loss: 0.1170 - acc: 0.976 - ETA: 0s - loss: 0.1172 - acc: 0.977 - 0s 599us/step - loss: 0.1159 - acc: 0.9784\n",
      "Epoch 80/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0375 - acc: 1.000 - ETA: 0s - loss: 0.0747 - acc: 0.989 - ETA: 0s - loss: 0.0946 - acc: 0.977 - ETA: 0s - loss: 0.0995 - acc: 0.971 - ETA: 0s - loss: 0.1101 - acc: 0.965 - ETA: 0s - loss: 0.1052 - acc: 0.967 - 0s 442us/step - loss: 0.0999 - acc: 0.9708\n",
      "Epoch 81/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1004 - acc: 0.968 - ETA: 0s - loss: 0.0883 - acc: 0.979 - ETA: 0s - loss: 0.0823 - acc: 0.982 - ETA: 0s - loss: 0.0756 - acc: 0.984 - ETA: 0s - loss: 0.0792 - acc: 0.985 - ETA: 0s - loss: 0.0961 - acc: 0.975 - 0s 454us/step - loss: 0.0905 - acc: 0.9772\n",
      "Epoch 82/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1697 - acc: 0.937 - ETA: 1s - loss: 0.1980 - acc: 0.921 - ETA: 0s - loss: 0.1393 - acc: 0.950 - ETA: 0s - loss: 0.1427 - acc: 0.950 - ETA: 0s - loss: 0.1350 - acc: 0.957 - ETA: 0s - loss: 0.1313 - acc: 0.957 - ETA: 0s - loss: 0.1236 - acc: 0.958 - ETA: 0s - loss: 0.1265 - acc: 0.956 - 0s 582us/step - loss: 0.1297 - acc: 0.9556\n",
      "Epoch 83/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0790 - acc: 0.968 - ETA: 0s - loss: 0.1059 - acc: 0.974 - ETA: 0s - loss: 0.1177 - acc: 0.968 - ETA: 0s - loss: 0.1045 - acc: 0.974 - ETA: 0s - loss: 0.1091 - acc: 0.972 - ETA: 0s - loss: 0.1107 - acc: 0.970 - ETA: 0s - loss: 0.1058 - acc: 0.972 - 0s 476us/step - loss: 0.1031 - acc: 0.9734\n",
      "Epoch 84/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0597 - acc: 1.000 - ETA: 0s - loss: 0.1053 - acc: 0.968 - ETA: 0s - loss: 0.0981 - acc: 0.968 - ETA: 0s - loss: 0.1003 - acc: 0.970 - ETA: 0s - loss: 0.1024 - acc: 0.970 - ETA: 0s - loss: 0.1029 - acc: 0.968 - ETA: 0s - loss: 0.1085 - acc: 0.967 - 0s 485us/step - loss: 0.1045 - acc: 0.9683\n",
      "Epoch 85/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0385 - acc: 1.000 - ETA: 0s - loss: 0.0881 - acc: 0.974 - ETA: 0s - loss: 0.1096 - acc: 0.965 - ETA: 0s - loss: 0.1021 - acc: 0.972 - ETA: 0s - loss: 0.1104 - acc: 0.968 - ETA: 0s - loss: 0.1055 - acc: 0.971 - 0s 442us/step - loss: 0.1036 - acc: 0.9695\n",
      "Epoch 86/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0405 - acc: 1.000 - ETA: 0s - loss: 0.0993 - acc: 0.974 - ETA: 0s - loss: 0.1060 - acc: 0.962 - ETA: 0s - loss: 0.1100 - acc: 0.968 - ETA: 0s - loss: 0.1069 - acc: 0.972 - ETA: 0s - loss: 0.1009 - acc: 0.975 - ETA: 0s - loss: 0.0959 - acc: 0.976 - 0s 516us/step - loss: 0.0950 - acc: 0.9784\n",
      "Epoch 87/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1769 - acc: 0.968 - ETA: 0s - loss: 0.1286 - acc: 0.963 - ETA: 0s - loss: 0.1116 - acc: 0.971 - ETA: 0s - loss: 0.0978 - acc: 0.979 - ETA: 0s - loss: 0.0912 - acc: 0.980 - ETA: 0s - loss: 0.0871 - acc: 0.978 - 0s 457us/step - loss: 0.0900 - acc: 0.9759\n",
      "Epoch 88/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1152 - acc: 0.968 - ETA: 0s - loss: 0.0859 - acc: 0.974 - ETA: 0s - loss: 0.0863 - acc: 0.981 - ETA: 0s - loss: 0.0749 - acc: 0.981 - ETA: 0s - loss: 0.0826 - acc: 0.978 - ETA: 0s - loss: 0.0893 - acc: 0.975 - 0s 420us/step - loss: 0.0858 - acc: 0.9772\n",
      "Epoch 89/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.937 - ETA: 0s - loss: 0.1572 - acc: 0.947 - ETA: 0s - loss: 0.1331 - acc: 0.956 - ETA: 0s - loss: 0.1331 - acc: 0.959 - ETA: 0s - loss: 0.1229 - acc: 0.963 - ETA: 0s - loss: 0.1181 - acc: 0.965 - ETA: 0s - loss: 0.1156 - acc: 0.968 - 0s 577us/step - loss: 0.1115 - acc: 0.9695\n",
      "Epoch 90/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0150 - acc: 1.000 - ETA: 0s - loss: 0.0827 - acc: 0.962 - ETA: 0s - loss: 0.1024 - acc: 0.959 - ETA: 0s - loss: 0.1064 - acc: 0.966 - ETA: 0s - loss: 0.1046 - acc: 0.968 - ETA: 0s - loss: 0.1015 - acc: 0.971 - ETA: 0s - loss: 0.1016 - acc: 0.970 - ETA: 0s - loss: 0.1088 - acc: 0.965 - ETA: 0s - loss: 0.1034 - acc: 0.967 - 0s 607us/step - loss: 0.1066 - acc: 0.9657\n",
      "Epoch 91/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1497 - acc: 0.968 - ETA: 0s - loss: 0.1309 - acc: 0.956 - ETA: 0s - loss: 0.0894 - acc: 0.975 - ETA: 0s - loss: 0.1000 - acc: 0.968 - ETA: 0s - loss: 0.0952 - acc: 0.970 - ETA: 0s - loss: 0.0945 - acc: 0.972 - ETA: 0s - loss: 0.0877 - acc: 0.976 - 0s 504us/step - loss: 0.0897 - acc: 0.9772\n",
      "Epoch 92/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0295 - acc: 1.000 - ETA: 0s - loss: 0.0769 - acc: 0.989 - ETA: 0s - loss: 0.0779 - acc: 0.992 - ETA: 0s - loss: 0.0913 - acc: 0.982 - ETA: 0s - loss: 0.0831 - acc: 0.984 - ETA: 0s - loss: 0.0784 - acc: 0.985 - ETA: 0s - loss: 0.0757 - acc: 0.990 - ETA: 0s - loss: 0.0716 - acc: 0.990 - ETA: 0s - loss: 0.0716 - acc: 0.990 - ETA: 0s - loss: 0.0749 - acc: 0.987 - 1s 697us/step - loss: 0.0771 - acc: 0.9860\n",
      "Epoch 93/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0552 - acc: 1.000 - ETA: 0s - loss: 0.1096 - acc: 0.956 - ETA: 0s - loss: 0.1190 - acc: 0.965 - ETA: 0s - loss: 0.1158 - acc: 0.968 - ETA: 0s - loss: 0.1017 - acc: 0.973 - ETA: 0s - loss: 0.1028 - acc: 0.972 - 0s 445us/step - loss: 0.1025 - acc: 0.9734\n",
      "Epoch 94/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1166 - acc: 0.968 - ETA: 0s - loss: 0.0747 - acc: 0.981 - ETA: 0s - loss: 0.0902 - acc: 0.974 - ETA: 0s - loss: 0.0896 - acc: 0.973 - ETA: 0s - loss: 0.0855 - acc: 0.978 - ETA: 0s - loss: 0.0807 - acc: 0.980 - 0s 438us/step - loss: 0.0839 - acc: 0.9772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0844 - acc: 0.968 - ETA: 0s - loss: 0.0835 - acc: 0.968 - ETA: 0s - loss: 0.0894 - acc: 0.975 - ETA: 0s - loss: 0.1034 - acc: 0.972 - ETA: 0s - loss: 0.1009 - acc: 0.975 - ETA: 0s - loss: 0.0955 - acc: 0.975 - 0s 397us/step - loss: 0.0920 - acc: 0.9772\n",
      "Epoch 96/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1251 - acc: 0.968 - ETA: 0s - loss: 0.0746 - acc: 0.968 - ETA: 0s - loss: 0.0623 - acc: 0.981 - ETA: 0s - loss: 0.0742 - acc: 0.968 - ETA: 0s - loss: 0.0954 - acc: 0.963 - ETA: 0s - loss: 0.1038 - acc: 0.962 - ETA: 0s - loss: 0.1138 - acc: 0.959 - ETA: 0s - loss: 0.1126 - acc: 0.962 - ETA: 0s - loss: 0.1121 - acc: 0.964 - 0s 623us/step - loss: 0.1123 - acc: 0.9632\n",
      "Epoch 97/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.937 - ETA: 0s - loss: 0.0819 - acc: 0.976 - ETA: 0s - loss: 0.0860 - acc: 0.982 - ETA: 0s - loss: 0.0914 - acc: 0.978 - ETA: 0s - loss: 0.0996 - acc: 0.977 - ETA: 0s - loss: 0.0925 - acc: 0.977 - 0s 395us/step - loss: 0.0919 - acc: 0.9784\n",
      "Epoch 98/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0832 - acc: 0.968 - ETA: 0s - loss: 0.0812 - acc: 0.982 - ETA: 0s - loss: 0.0806 - acc: 0.984 - ETA: 0s - loss: 0.0840 - acc: 0.983 - ETA: 0s - loss: 0.0849 - acc: 0.981 - ETA: 0s - loss: 0.0870 - acc: 0.982 - ETA: 0s - loss: 0.0868 - acc: 0.981 - 0s 463us/step - loss: 0.0869 - acc: 0.9822\n",
      "Epoch 99/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.968 - ETA: 0s - loss: 0.0682 - acc: 0.984 - ETA: 0s - loss: 0.0719 - acc: 0.984 - ETA: 0s - loss: 0.0736 - acc: 0.986 - ETA: 0s - loss: 0.0793 - acc: 0.979 - ETA: 0s - loss: 0.0757 - acc: 0.983 - ETA: 0s - loss: 0.0740 - acc: 0.983 - ETA: 0s - loss: 0.0767 - acc: 0.981 - 0s 553us/step - loss: 0.0759 - acc: 0.9822\n",
      "Epoch 100/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1094 - acc: 0.968 - ETA: 0s - loss: 0.0549 - acc: 0.991 - ETA: 0s - loss: 0.0551 - acc: 0.988 - ETA: 0s - loss: 0.0650 - acc: 0.986 - ETA: 0s - loss: 0.0779 - acc: 0.978 - ETA: 0s - loss: 0.0772 - acc: 0.977 - ETA: 0s - loss: 0.0856 - acc: 0.975 - 0s 490us/step - loss: 0.0851 - acc: 0.9746\n",
      "Epoch 101/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0552 - acc: 1.000 - ETA: 0s - loss: 0.1006 - acc: 0.976 - ETA: 0s - loss: 0.0937 - acc: 0.981 - ETA: 0s - loss: 0.0946 - acc: 0.975 - ETA: 0s - loss: 0.1000 - acc: 0.973 - ETA: 0s - loss: 0.0932 - acc: 0.974 - ETA: 0s - loss: 0.1021 - acc: 0.968 - 0s 506us/step - loss: 0.1050 - acc: 0.9695\n",
      "Epoch 102/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0832 - acc: 0.937 - ETA: 0s - loss: 0.0936 - acc: 0.963 - ETA: 0s - loss: 0.0853 - acc: 0.968 - ETA: 0s - loss: 0.0788 - acc: 0.974 - ETA: 0s - loss: 0.0815 - acc: 0.973 - 0s 358us/step - loss: 0.0847 - acc: 0.9759\n",
      "Epoch 103/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.968 - ETA: 0s - loss: 0.0859 - acc: 0.984 - ETA: 0s - loss: 0.0722 - acc: 0.985 - ETA: 0s - loss: 0.0802 - acc: 0.984 - ETA: 0s - loss: 0.0764 - acc: 0.985 - 0s 353us/step - loss: 0.0805 - acc: 0.9822\n",
      "Epoch 104/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0744 - acc: 1.000 - ETA: 0s - loss: 0.0549 - acc: 0.987 - ETA: 0s - loss: 0.0736 - acc: 0.990 - ETA: 0s - loss: 0.0672 - acc: 0.990 - ETA: 0s - loss: 0.0817 - acc: 0.981 - ETA: 0s - loss: 0.0782 - acc: 0.982 - ETA: 0s - loss: 0.0849 - acc: 0.979 - 0s 472us/step - loss: 0.0847 - acc: 0.9810\n",
      "Epoch 105/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0822 - acc: 0.968 - ETA: 0s - loss: 0.0504 - acc: 0.989 - ETA: 0s - loss: 0.0670 - acc: 0.975 - ETA: 0s - loss: 0.0697 - acc: 0.972 - ETA: 0s - loss: 0.0768 - acc: 0.976 - ETA: 0s - loss: 0.0732 - acc: 0.980 - ETA: 0s - loss: 0.0750 - acc: 0.981 - 0s 481us/step - loss: 0.0791 - acc: 0.9784\n",
      "Epoch 106/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0903 - acc: 0.968 - ETA: 0s - loss: 0.0738 - acc: 0.979 - ETA: 0s - loss: 0.0659 - acc: 0.982 - ETA: 0s - loss: 0.0645 - acc: 0.980 - ETA: 0s - loss: 0.0661 - acc: 0.979 - ETA: 0s - loss: 0.0649 - acc: 0.980 - ETA: 0s - loss: 0.0690 - acc: 0.979 - 0s 457us/step - loss: 0.0657 - acc: 0.9810\n",
      "Epoch 107/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0744 - acc: 1.000 - ETA: 0s - loss: 0.0546 - acc: 0.993 - ETA: 0s - loss: 0.0656 - acc: 0.982 - ETA: 0s - loss: 0.0869 - acc: 0.971 - ETA: 0s - loss: 0.0832 - acc: 0.973 - ETA: 0s - loss: 0.0796 - acc: 0.975 - 0s 400us/step - loss: 0.0775 - acc: 0.9759\n",
      "Epoch 108/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1296 - acc: 0.968 - ETA: 0s - loss: 0.1085 - acc: 0.975 - ETA: 0s - loss: 0.1190 - acc: 0.973 - ETA: 0s - loss: 0.1086 - acc: 0.976 - ETA: 0s - loss: 0.1080 - acc: 0.978 - ETA: 0s - loss: 0.1124 - acc: 0.974 - ETA: 0s - loss: 0.1007 - acc: 0.977 - ETA: 0s - loss: 0.0942 - acc: 0.977 - ETA: 0s - loss: 0.0881 - acc: 0.979 - 1s 679us/step - loss: 0.0889 - acc: 0.9746\n",
      "Epoch 109/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1366 - acc: 0.937 - ETA: 0s - loss: 0.0874 - acc: 0.962 - ETA: 0s - loss: 0.0967 - acc: 0.965 - ETA: 0s - loss: 0.0822 - acc: 0.973 - ETA: 0s - loss: 0.0750 - acc: 0.977 - ETA: 0s - loss: 0.0746 - acc: 0.981 - 0s 416us/step - loss: 0.0780 - acc: 0.9797\n",
      "Epoch 110/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1434 - acc: 0.937 - ETA: 0s - loss: 0.0738 - acc: 0.981 - ETA: 0s - loss: 0.0730 - acc: 0.981 - ETA: 0s - loss: 0.0816 - acc: 0.977 - ETA: 0s - loss: 0.0821 - acc: 0.978 - ETA: 0s - loss: 0.0783 - acc: 0.980 - ETA: 0s - loss: 0.0776 - acc: 0.982 - 0s 512us/step - loss: 0.0744 - acc: 0.9822\n",
      "Epoch 111/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.968 - ETA: 0s - loss: 0.0721 - acc: 0.989 - ETA: 0s - loss: 0.0705 - acc: 0.981 - ETA: 0s - loss: 0.0816 - acc: 0.977 - ETA: 0s - loss: 0.0852 - acc: 0.976 - ETA: 0s - loss: 0.0791 - acc: 0.977 - ETA: 0s - loss: 0.0808 - acc: 0.975 - 0s 492us/step - loss: 0.0819 - acc: 0.9772\n",
      "Epoch 112/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1453 - acc: 0.968 - ETA: 0s - loss: 0.0944 - acc: 0.975 - ETA: 0s - loss: 0.0838 - acc: 0.978 - ETA: 0s - loss: 0.0754 - acc: 0.981 - ETA: 0s - loss: 0.0819 - acc: 0.978 - ETA: 0s - loss: 0.0818 - acc: 0.979 - 0s 412us/step - loss: 0.0819 - acc: 0.9797\n",
      "Epoch 113/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0287 - acc: 1.000 - ETA: 0s - loss: 0.0506 - acc: 0.981 - ETA: 0s - loss: 0.0589 - acc: 0.984 - ETA: 0s - loss: 0.0609 - acc: 0.986 - ETA: 0s - loss: 0.0625 - acc: 0.986 - ETA: 0s - loss: 0.0657 - acc: 0.987 - ETA: 0s - loss: 0.0728 - acc: 0.983 - 0s 452us/step - loss: 0.0719 - acc: 0.9835\n",
      "Epoch 114/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0729 - acc: 0.968 - ETA: 0s - loss: 0.0558 - acc: 0.982 - ETA: 0s - loss: 0.0657 - acc: 0.981 - ETA: 0s - loss: 0.0622 - acc: 0.984 - ETA: 0s - loss: 0.0609 - acc: 0.985 - ETA: 0s - loss: 0.0610 - acc: 0.988 - 0s 410us/step - loss: 0.0627 - acc: 0.9873\n",
      "Epoch 115/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1286 - acc: 0.937 - ETA: 0s - loss: 0.0821 - acc: 0.963 - ETA: 0s - loss: 0.0769 - acc: 0.968 - ETA: 0s - loss: 0.0677 - acc: 0.970 - ETA: 0s - loss: 0.0660 - acc: 0.974 - ETA: 0s - loss: 0.0654 - acc: 0.975 - ETA: 0s - loss: 0.0743 - acc: 0.974 - 0s 522us/step - loss: 0.0723 - acc: 0.9772\n",
      "Epoch 116/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0489 - acc: 1.000 - ETA: 0s - loss: 0.0678 - acc: 0.987 - ETA: 0s - loss: 0.0672 - acc: 0.988 - ETA: 0s - loss: 0.0773 - acc: 0.981 - ETA: 0s - loss: 0.0771 - acc: 0.983 - ETA: 0s - loss: 0.0799 - acc: 0.978 - ETA: 0s - loss: 0.0710 - acc: 0.980 - 0s 529us/step - loss: 0.0663 - acc: 0.9822\n",
      "Epoch 117/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0151 - acc: 1.000 - ETA: 0s - loss: 0.0506 - acc: 0.993 - ETA: 0s - loss: 0.0418 - acc: 0.995 - ETA: 0s - loss: 0.0347 - acc: 0.996 - ETA: 0s - loss: 0.0383 - acc: 0.993 - ETA: 0s - loss: 0.0421 - acc: 0.993 - ETA: 0s - loss: 0.0583 - acc: 0.985 - 0s 495us/step - loss: 0.0561 - acc: 0.9873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.2287 - acc: 0.906 - ETA: 0s - loss: 0.0803 - acc: 0.979 - ETA: 0s - loss: 0.0780 - acc: 0.981 - ETA: 0s - loss: 0.0750 - acc: 0.982 - ETA: 0s - loss: 0.0729 - acc: 0.982 - ETA: 0s - loss: 0.0710 - acc: 0.983 - 0s 448us/step - loss: 0.0702 - acc: 0.9848\n",
      "Epoch 119/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0553 - acc: 0.989 - ETA: 0s - loss: 0.0560 - acc: 0.987 - ETA: 0s - loss: 0.0577 - acc: 0.983 - ETA: 0s - loss: 0.0582 - acc: 0.982 - ETA: 0s - loss: 0.0569 - acc: 0.983 - ETA: 0s - loss: 0.0578 - acc: 0.984 - 0s 468us/step - loss: 0.0582 - acc: 0.9848\n",
      "Epoch 120/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0452 - acc: 1.000 - ETA: 0s - loss: 0.0495 - acc: 0.992 - ETA: 0s - loss: 0.0497 - acc: 0.988 - ETA: 0s - loss: 0.0472 - acc: 0.989 - ETA: 0s - loss: 0.0540 - acc: 0.987 - ETA: 0s - loss: 0.0555 - acc: 0.987 - ETA: 0s - loss: 0.0584 - acc: 0.986 - 0s 453us/step - loss: 0.0583 - acc: 0.9873\n",
      "Epoch 121/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0400 - acc: 1.000 - ETA: 0s - loss: 0.0721 - acc: 0.981 - ETA: 0s - loss: 0.0828 - acc: 0.975 - ETA: 0s - loss: 0.0751 - acc: 0.979 - ETA: 0s - loss: 0.0778 - acc: 0.977 - ETA: 0s - loss: 0.0746 - acc: 0.979 - ETA: 0s - loss: 0.0730 - acc: 0.977 - 0s 458us/step - loss: 0.0730 - acc: 0.9772\n",
      "Epoch 122/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0260 - acc: 1.000 - ETA: 0s - loss: 0.0676 - acc: 0.981 - ETA: 0s - loss: 0.0572 - acc: 0.982 - ETA: 0s - loss: 0.0500 - acc: 0.984 - ETA: 0s - loss: 0.0527 - acc: 0.982 - ETA: 0s - loss: 0.0570 - acc: 0.980 - ETA: 0s - loss: 0.0625 - acc: 0.979 - 0s 468us/step - loss: 0.0630 - acc: 0.9797\n",
      "Epoch 123/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0400 - acc: 1.000 - ETA: 0s - loss: 0.0513 - acc: 0.994 - ETA: 0s - loss: 0.0654 - acc: 0.984 - ETA: 0s - loss: 0.0645 - acc: 0.982 - ETA: 0s - loss: 0.0689 - acc: 0.983 - ETA: 0s - loss: 0.0688 - acc: 0.983 - 0s 388us/step - loss: 0.0681 - acc: 0.9835\n",
      "Epoch 124/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1081 - acc: 0.968 - ETA: 0s - loss: 0.0664 - acc: 0.984 - ETA: 0s - loss: 0.0563 - acc: 0.989 - ETA: 0s - loss: 0.0539 - acc: 0.990 - ETA: 0s - loss: 0.0464 - acc: 0.993 - ETA: 0s - loss: 0.0430 - acc: 0.994 - 0s 415us/step - loss: 0.0446 - acc: 0.9937\n",
      "Epoch 125/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1686 - acc: 0.937 - ETA: 0s - loss: 0.0987 - acc: 0.975 - ETA: 0s - loss: 0.0742 - acc: 0.982 - ETA: 0s - loss: 0.0605 - acc: 0.985 - ETA: 0s - loss: 0.0688 - acc: 0.984 - ETA: 0s - loss: 0.0701 - acc: 0.983 - 0s 397us/step - loss: 0.0688 - acc: 0.9835\n",
      "Epoch 126/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0140 - acc: 1.000 - ETA: 0s - loss: 0.0454 - acc: 0.984 - ETA: 0s - loss: 0.0447 - acc: 0.987 - ETA: 0s - loss: 0.0611 - acc: 0.979 - ETA: 0s - loss: 0.0687 - acc: 0.979 - 0s 360us/step - loss: 0.0645 - acc: 0.9822\n",
      "Epoch 127/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1089 - acc: 0.968 - ETA: 0s - loss: 0.0446 - acc: 0.989 - ETA: 0s - loss: 0.0565 - acc: 0.985 - ETA: 0s - loss: 0.0599 - acc: 0.984 - ETA: 0s - loss: 0.0591 - acc: 0.983 - 0s 346us/step - loss: 0.0527 - acc: 0.9860\n",
      "Epoch 128/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0719 - acc: 0.968 - ETA: 0s - loss: 0.0842 - acc: 0.974 - ETA: 0s - loss: 0.0644 - acc: 0.985 - ETA: 0s - loss: 0.0640 - acc: 0.982 - ETA: 0s - loss: 0.0635 - acc: 0.981 - 0s 350us/step - loss: 0.0618 - acc: 0.9810\n",
      "Epoch 129/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1133 - acc: 0.968 - ETA: 0s - loss: 0.0799 - acc: 0.984 - ETA: 0s - loss: 0.0710 - acc: 0.984 - ETA: 0s - loss: 0.0648 - acc: 0.987 - ETA: 0s - loss: 0.0688 - acc: 0.984 - 0s 359us/step - loss: 0.0630 - acc: 0.9860\n",
      "Epoch 130/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0611 - acc: 1.000 - ETA: 0s - loss: 0.0596 - acc: 0.989 - ETA: 0s - loss: 0.0703 - acc: 0.977 - ETA: 0s - loss: 0.0744 - acc: 0.976 - ETA: 0s - loss: 0.0707 - acc: 0.980 - 0s 346us/step - loss: 0.0658 - acc: 0.9835\n",
      "Epoch 131/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0399 - acc: 1.000 - ETA: 0s - loss: 0.0459 - acc: 0.987 - ETA: 0s - loss: 0.0392 - acc: 0.993 - ETA: 0s - loss: 0.0370 - acc: 0.995 - ETA: 0s - loss: 0.0446 - acc: 0.993 - ETA: 0s - loss: 0.0501 - acc: 0.990 - 0s 382us/step - loss: 0.0506 - acc: 0.9898\n",
      "Epoch 132/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1120 - acc: 0.937 - ETA: 0s - loss: 0.0849 - acc: 0.974 - ETA: 0s - loss: 0.0663 - acc: 0.983 - ETA: 0s - loss: 0.0743 - acc: 0.976 - ETA: 0s - loss: 0.0673 - acc: 0.980 - ETA: 0s - loss: 0.0668 - acc: 0.981 - 0s 388us/step - loss: 0.0705 - acc: 0.9797\n",
      "Epoch 133/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0393 - acc: 1.000 - ETA: 0s - loss: 0.0675 - acc: 0.986 - ETA: 0s - loss: 0.0815 - acc: 0.981 - ETA: 0s - loss: 0.0815 - acc: 0.977 - ETA: 0s - loss: 0.0768 - acc: 0.978 - 0s 341us/step - loss: 0.0828 - acc: 0.9772\n",
      "Epoch 134/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1422 - acc: 0.968 - ETA: 0s - loss: 0.0765 - acc: 0.981 - ETA: 0s - loss: 0.0588 - acc: 0.984 - ETA: 0s - loss: 0.0583 - acc: 0.987 - ETA: 0s - loss: 0.0528 - acc: 0.990 - 0s 367us/step - loss: 0.0561 - acc: 0.9898\n",
      "Epoch 135/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0153 - acc: 1.000 - ETA: 0s - loss: 0.0480 - acc: 0.982 - ETA: 0s - loss: 0.0485 - acc: 0.985 - ETA: 0s - loss: 0.0485 - acc: 0.986 - ETA: 0s - loss: 0.0470 - acc: 0.986 - 0s 353us/step - loss: 0.0454 - acc: 0.9873\n",
      "Epoch 136/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0172 - acc: 1.000 - ETA: 0s - loss: 0.0506 - acc: 0.986 - ETA: 0s - loss: 0.0677 - acc: 0.983 - ETA: 0s - loss: 0.0677 - acc: 0.980 - ETA: 0s - loss: 0.0605 - acc: 0.985 - 0s 353us/step - loss: 0.0614 - acc: 0.9848\n",
      "Epoch 137/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0959 - acc: 0.968 - ETA: 0s - loss: 0.0602 - acc: 0.979 - ETA: 0s - loss: 0.0527 - acc: 0.983 - ETA: 0s - loss: 0.0530 - acc: 0.985 - ETA: 0s - loss: 0.0507 - acc: 0.985 - ETA: 0s - loss: 0.0647 - acc: 0.981 - 0s 374us/step - loss: 0.0633 - acc: 0.9822\n",
      "Epoch 138/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0203 - acc: 1.000 - ETA: 0s - loss: 0.0454 - acc: 0.984 - ETA: 0s - loss: 0.0542 - acc: 0.982 - ETA: 0s - loss: 0.0542 - acc: 0.986 - ETA: 0s - loss: 0.0601 - acc: 0.983 - ETA: 0s - loss: 0.0586 - acc: 0.985 - 0s 386us/step - loss: 0.0588 - acc: 0.9848\n",
      "Epoch 139/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0554 - acc: 1.000 - ETA: 0s - loss: 0.0565 - acc: 0.979 - ETA: 0s - loss: 0.0556 - acc: 0.983 - ETA: 0s - loss: 0.0654 - acc: 0.978 - ETA: 0s - loss: 0.0699 - acc: 0.976 - 0s 352us/step - loss: 0.0687 - acc: 0.9759\n",
      "Epoch 140/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0785 - acc: 1.000 - ETA: 0s - loss: 0.0406 - acc: 0.994 - ETA: 0s - loss: 0.0448 - acc: 0.993 - ETA: 0s - loss: 0.0568 - acc: 0.989 - ETA: 0s - loss: 0.0647 - acc: 0.981 - 0s 362us/step - loss: 0.0623 - acc: 0.9822\n",
      "Epoch 141/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0399 - acc: 1.000 - ETA: 0s - loss: 0.0875 - acc: 0.963 - ETA: 0s - loss: 0.0829 - acc: 0.974 - ETA: 0s - loss: 0.0786 - acc: 0.978 - ETA: 0s - loss: 0.0743 - acc: 0.979 - 0s 376us/step - loss: 0.0678 - acc: 0.9822\n",
      "Epoch 142/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1427 - acc: 0.968 - ETA: 0s - loss: 0.0566 - acc: 0.984 - ETA: 0s - loss: 0.0493 - acc: 0.988 - ETA: 0s - loss: 0.0516 - acc: 0.988 - ETA: 0s - loss: 0.0521 - acc: 0.989 - 0s 355us/step - loss: 0.0503 - acc: 0.9898\n",
      "Epoch 143/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0836 - acc: 0.968 - ETA: 0s - loss: 0.0481 - acc: 0.984 - ETA: 0s - loss: 0.0584 - acc: 0.980 - ETA: 0s - loss: 0.0579 - acc: 0.979 - ETA: 0s - loss: 0.0542 - acc: 0.979 - 0s 358us/step - loss: 0.0503 - acc: 0.9835\n",
      "Epoch 144/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0209 - acc: 1.000 - ETA: 0s - loss: 0.0519 - acc: 0.987 - ETA: 0s - loss: 0.0602 - acc: 0.981 - ETA: 0s - loss: 0.0542 - acc: 0.985 - ETA: 0s - loss: 0.0463 - acc: 0.987 - 0s 354us/step - loss: 0.0478 - acc: 0.9860\n",
      "Epoch 145/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0233 - acc: 1.000 - ETA: 0s - loss: 0.0558 - acc: 0.989 - ETA: 0s - loss: 0.0463 - acc: 0.991 - ETA: 0s - loss: 0.0582 - acc: 0.983 - ETA: 0s - loss: 0.0584 - acc: 0.984 - 0s 353us/step - loss: 0.0568 - acc: 0.9848\n",
      "Epoch 146/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1124 - acc: 0.968 - ETA: 0s - loss: 0.0510 - acc: 0.989 - ETA: 0s - loss: 0.0726 - acc: 0.980 - ETA: 0s - loss: 0.0680 - acc: 0.982 - ETA: 0s - loss: 0.0608 - acc: 0.986 - 0s 335us/step - loss: 0.0541 - acc: 0.9886\n",
      "Epoch 147/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0935 - acc: 0.968 - ETA: 0s - loss: 0.0550 - acc: 0.977 - ETA: 0s - loss: 0.0492 - acc: 0.984 - ETA: 0s - loss: 0.0506 - acc: 0.985 - ETA: 0s - loss: 0.0461 - acc: 0.987 - 0s 334us/step - loss: 0.0436 - acc: 0.9886\n",
      "Epoch 148/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0274 - acc: 1.000 - ETA: 0s - loss: 0.0590 - acc: 0.982 - ETA: 0s - loss: 0.0646 - acc: 0.979 - ETA: 0s - loss: 0.0653 - acc: 0.977 - ETA: 0s - loss: 0.0618 - acc: 0.978 - 0s 331us/step - loss: 0.0671 - acc: 0.9784\n",
      "Epoch 149/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.968 - ETA: 0s - loss: 0.0365 - acc: 0.994 - ETA: 0s - loss: 0.0391 - acc: 0.997 - ETA: 0s - loss: 0.0412 - acc: 0.996 - ETA: 0s - loss: 0.0416 - acc: 0.995 - ETA: 0s - loss: 0.0418 - acc: 0.993 - 0s 372us/step - loss: 0.0417 - acc: 0.9937\n",
      "Epoch 150/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0683 - acc: 0.974 - ETA: 0s - loss: 0.0675 - acc: 0.974 - ETA: 0s - loss: 0.0657 - acc: 0.972 - ETA: 0s - loss: 0.0665 - acc: 0.976 - 0s 343us/step - loss: 0.0616 - acc: 0.9797\n",
      "Epoch 151/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0953 - acc: 0.968 - ETA: 0s - loss: 0.0579 - acc: 0.984 - ETA: 0s - loss: 0.0590 - acc: 0.983 - ETA: 0s - loss: 0.0614 - acc: 0.980 - ETA: 0s - loss: 0.0524 - acc: 0.985 - 0s 349us/step - loss: 0.0578 - acc: 0.9810\n",
      "Epoch 152/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0110 - acc: 1.000 - ETA: 0s - loss: 0.0287 - acc: 0.994 - ETA: 0s - loss: 0.0428 - acc: 0.988 - ETA: 0s - loss: 0.0392 - acc: 0.990 - ETA: 0s - loss: 0.0432 - acc: 0.988 - 0s 345us/step - loss: 0.0438 - acc: 0.9873\n",
      "Epoch 153/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0369 - acc: 0.968 - ETA: 0s - loss: 0.0203 - acc: 0.994 - ETA: 0s - loss: 0.0360 - acc: 0.991 - ETA: 0s - loss: 0.0380 - acc: 0.990 - ETA: 0s - loss: 0.0457 - acc: 0.988 - 0s 359us/step - loss: 0.0480 - acc: 0.9873\n",
      "Epoch 154/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0209 - acc: 1.000 - ETA: 0s - loss: 0.0415 - acc: 0.984 - ETA: 0s - loss: 0.0435 - acc: 0.985 - ETA: 0s - loss: 0.0485 - acc: 0.986 - ETA: 0s - loss: 0.0518 - acc: 0.983 - 0s 343us/step - loss: 0.0525 - acc: 0.9835\n",
      "Epoch 155/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - ETA: 0s - loss: 0.0654 - acc: 0.979 - ETA: 0s - loss: 0.0550 - acc: 0.983 - ETA: 0s - loss: 0.0544 - acc: 0.984 - ETA: 0s - loss: 0.0516 - acc: 0.985 - 0s 345us/step - loss: 0.0485 - acc: 0.9860\n",
      "Epoch 156/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0512 - acc: 1.000 - ETA: 0s - loss: 0.0506 - acc: 0.994 - ETA: 0s - loss: 0.0508 - acc: 0.994 - ETA: 0s - loss: 0.0483 - acc: 0.994 - ETA: 0s - loss: 0.0460 - acc: 0.992 - 0s 341us/step - loss: 0.0448 - acc: 0.9937\n",
      "Epoch 157/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0152 - acc: 1.000 - ETA: 0s - loss: 0.0551 - acc: 0.984 - ETA: 0s - loss: 0.0570 - acc: 0.983 - ETA: 0s - loss: 0.0493 - acc: 0.986 - ETA: 0s - loss: 0.0494 - acc: 0.983 - 0s 350us/step - loss: 0.0462 - acc: 0.9848\n",
      "Epoch 158/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0366 - acc: 1.000 - ETA: 0s - loss: 0.0554 - acc: 0.984 - ETA: 0s - loss: 0.0484 - acc: 0.984 - ETA: 0s - loss: 0.0562 - acc: 0.981 - ETA: 0s - loss: 0.0665 - acc: 0.976 - ETA: 0s - loss: 0.0616 - acc: 0.979 - 0s 391us/step - loss: 0.0639 - acc: 0.9784\n",
      "Epoch 159/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0353 - acc: 1.000 - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0393 - acc: 0.991 - ETA: 0s - loss: 0.0373 - acc: 0.990 - ETA: 0s - loss: 0.0458 - acc: 0.986 - 0s 353us/step - loss: 0.0439 - acc: 0.9873\n",
      "Epoch 160/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0517 - acc: 0.968 - ETA: 0s - loss: 0.0318 - acc: 0.989 - ETA: 0s - loss: 0.0329 - acc: 0.992 - ETA: 0s - loss: 0.0442 - acc: 0.990 - ETA: 0s - loss: 0.0422 - acc: 0.990 - 0s 341us/step - loss: 0.0466 - acc: 0.9898\n",
      "Epoch 161/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.968 - ETA: 0s - loss: 0.0810 - acc: 0.968 - ETA: 0s - loss: 0.0509 - acc: 0.982 - ETA: 0s - loss: 0.0511 - acc: 0.979 - ETA: 0s - loss: 0.0473 - acc: 0.983 - ETA: 0s - loss: 0.0512 - acc: 0.985 - 0s 378us/step - loss: 0.0499 - acc: 0.9860\n",
      "Epoch 162/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0138 - acc: 1.000 - ETA: 0s - loss: 0.0381 - acc: 0.986 - ETA: 0s - loss: 0.0350 - acc: 0.989 - ETA: 0s - loss: 0.0354 - acc: 0.989 - ETA: 0s - loss: 0.0436 - acc: 0.985 - 0s 355us/step - loss: 0.0440 - acc: 0.9860\n",
      "Epoch 163/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0537 - acc: 0.968 - ETA: 0s - loss: 0.0648 - acc: 0.984 - ETA: 0s - loss: 0.0520 - acc: 0.985 - ETA: 0s - loss: 0.0443 - acc: 0.988 - ETA: 0s - loss: 0.0424 - acc: 0.989 - 0s 356us/step - loss: 0.0511 - acc: 0.9860\n",
      "Epoch 164/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0132 - acc: 1.000 - ETA: 0s - loss: 0.0280 - acc: 0.994 - ETA: 0s - loss: 0.0339 - acc: 0.991 - ETA: 0s - loss: 0.0359 - acc: 0.990 - ETA: 0s - loss: 0.0404 - acc: 0.989 - ETA: 0s - loss: 0.0442 - acc: 0.988 - 0s 386us/step - loss: 0.0455 - acc: 0.9873\n",
      "Epoch 165/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0235 - acc: 1.000 - ETA: 0s - loss: 0.0610 - acc: 0.987 - ETA: 0s - loss: 0.0527 - acc: 0.989 - ETA: 0s - loss: 0.0460 - acc: 0.992 - 0s 352us/step - loss: 0.0458 - acc: 0.9924\n",
      "Epoch 166/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1058 - acc: 0.968 - ETA: 0s - loss: 0.0500 - acc: 0.987 - ETA: 0s - loss: 0.0463 - acc: 0.989 - ETA: 0s - loss: 0.0512 - acc: 0.984 - ETA: 0s - loss: 0.0412 - acc: 0.988 - ETA: 0s - loss: 0.0417 - acc: 0.988 - 0s 395us/step - loss: 0.0434 - acc: 0.9873\n",
      "Epoch 167/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1202 - acc: 0.968 - ETA: 0s - loss: 0.0514 - acc: 0.989 - ETA: 0s - loss: 0.0592 - acc: 0.985 - ETA: 0s - loss: 0.0689 - acc: 0.980 - ETA: 0s - loss: 0.0658 - acc: 0.980 - 0s 352us/step - loss: 0.0582 - acc: 0.9835\n",
      "Epoch 168/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0419 - acc: 0.986 - ETA: 0s - loss: 0.0366 - acc: 0.988 - ETA: 0s - loss: 0.0410 - acc: 0.988 - ETA: 0s - loss: 0.0466 - acc: 0.985 - 0s 358us/step - loss: 0.0477 - acc: 0.9848\n",
      "Epoch 169/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0253 - acc: 1.000 - ETA: 0s - loss: 0.0258 - acc: 1.000 - ETA: 0s - loss: 0.0285 - acc: 0.994 - ETA: 0s - loss: 0.0471 - acc: 0.988 - ETA: 0s - loss: 0.0418 - acc: 0.990 - ETA: 0s - loss: 0.0423 - acc: 0.989 - 0s 388us/step - loss: 0.0413 - acc: 0.9898\n",
      "Epoch 170/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0224 - acc: 1.000 - ETA: 0s - loss: 0.0429 - acc: 0.984 - ETA: 0s - loss: 0.0344 - acc: 0.988 - ETA: 0s - loss: 0.0285 - acc: 0.992 - ETA: 0s - loss: 0.0346 - acc: 0.989 - 0s 348us/step - loss: 0.0346 - acc: 0.9898\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788/788 [==============================] - ETA: 0s - loss: 0.1077 - acc: 0.968 - ETA: 0s - loss: 0.0465 - acc: 0.989 - ETA: 0s - loss: 0.0498 - acc: 0.987 - ETA: 0s - loss: 0.0486 - acc: 0.988 - ETA: 0s - loss: 0.0431 - acc: 0.991 - ETA: 0s - loss: 0.0449 - acc: 0.990 - 0s 378us/step - loss: 0.0437 - acc: 0.9911\n",
      "Epoch 172/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0245 - acc: 0.994 - ETA: 0s - loss: 0.0287 - acc: 0.994 - ETA: 0s - loss: 0.0418 - acc: 0.990 - ETA: 0s - loss: 0.0365 - acc: 0.992 - 0s 348us/step - loss: 0.0380 - acc: 0.9911\n",
      "Epoch 173/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0291 - acc: 1.000 - ETA: 0s - loss: 0.0582 - acc: 0.979 - ETA: 0s - loss: 0.0552 - acc: 0.983 - ETA: 0s - loss: 0.0518 - acc: 0.984 - ETA: 0s - loss: 0.0537 - acc: 0.983 - 0s 357us/step - loss: 0.0499 - acc: 0.9848\n",
      "Epoch 174/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0135 - acc: 1.000 - ETA: 0s - loss: 0.0227 - acc: 0.994 - ETA: 0s - loss: 0.0417 - acc: 0.985 - ETA: 0s - loss: 0.0336 - acc: 0.990 - ETA: 0s - loss: 0.0408 - acc: 0.987 - 0s 352us/step - loss: 0.0455 - acc: 0.9860\n",
      "Epoch 175/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0288 - acc: 0.995 - ETA: 0s - loss: 0.0310 - acc: 0.992 - ETA: 0s - loss: 0.0359 - acc: 0.990 - ETA: 0s - loss: 0.0359 - acc: 0.991 - 0s 340us/step - loss: 0.0395 - acc: 0.9886\n",
      "Epoch 176/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0387 - acc: 1.000 - ETA: 0s - loss: 0.0364 - acc: 0.989 - ETA: 0s - loss: 0.0422 - acc: 0.988 - ETA: 0s - loss: 0.0389 - acc: 0.988 - ETA: 0s - loss: 0.0371 - acc: 0.991 - 0s 345us/step - loss: 0.0347 - acc: 0.9911\n",
      "Epoch 177/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0291 - acc: 1.000 - ETA: 0s - loss: 0.0315 - acc: 0.994 - ETA: 0s - loss: 0.0392 - acc: 0.988 - ETA: 0s - loss: 0.0371 - acc: 0.990 - ETA: 0s - loss: 0.0378 - acc: 0.991 - 0s 350us/step - loss: 0.0349 - acc: 0.9924\n",
      "Epoch 178/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0151 - acc: 1.000 - ETA: 0s - loss: 0.0226 - acc: 0.994 - ETA: 0s - loss: 0.0398 - acc: 0.991 - ETA: 0s - loss: 0.0507 - acc: 0.988 - ETA: 0s - loss: 0.0623 - acc: 0.982 - 0s 345us/step - loss: 0.0582 - acc: 0.9835\n",
      "Epoch 179/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0233 - acc: 1.000 - ETA: 0s - loss: 0.0227 - acc: 0.994 - ETA: 0s - loss: 0.0329 - acc: 0.988 - ETA: 0s - loss: 0.0298 - acc: 0.991 - ETA: 0s - loss: 0.0360 - acc: 0.990 - ETA: 0s - loss: 0.0409 - acc: 0.989 - 0s 391us/step - loss: 0.0400 - acc: 0.9898\n",
      "Epoch 180/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.968 - ETA: 0s - loss: 0.0326 - acc: 0.989 - ETA: 0s - loss: 0.0246 - acc: 0.994 - ETA: 0s - loss: 0.0354 - acc: 0.988 - ETA: 0s - loss: 0.0350 - acc: 0.987 - 0s 355us/step - loss: 0.0318 - acc: 0.9898\n",
      "Epoch 181/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0247 - acc: 1.000 - ETA: 0s - loss: 0.0287 - acc: 0.991 - ETA: 0s - loss: 0.0363 - acc: 0.989 - ETA: 0s - loss: 0.0426 - acc: 0.989 - ETA: 0s - loss: 0.0420 - acc: 0.990 - 0s 353us/step - loss: 0.0417 - acc: 0.9898\n",
      "Epoch 182/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.1109 - acc: 0.968 - ETA: 0s - loss: 0.0392 - acc: 0.994 - ETA: 0s - loss: 0.0346 - acc: 0.993 - ETA: 0s - loss: 0.0337 - acc: 0.995 - ETA: 0s - loss: 0.0337 - acc: 0.995 - 0s 355us/step - loss: 0.0356 - acc: 0.9937\n",
      "Epoch 183/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.968 - ETA: 0s - loss: 0.0602 - acc: 0.974 - ETA: 0s - loss: 0.0513 - acc: 0.980 - ETA: 0s - loss: 0.0431 - acc: 0.986 - ETA: 0s - loss: 0.0491 - acc: 0.983 - 0s 359us/step - loss: 0.0483 - acc: 0.9848\n",
      "Epoch 184/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0244 - acc: 0.994 - ETA: 0s - loss: 0.0286 - acc: 0.994 - ETA: 0s - loss: 0.0237 - acc: 0.996 - ETA: 0s - loss: 0.0284 - acc: 0.994 - 0s 359us/step - loss: 0.0415 - acc: 0.9898\n",
      "Epoch 185/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0288 - acc: 1.000 - ETA: 0s - loss: 0.0284 - acc: 0.994 - ETA: 0s - loss: 0.0383 - acc: 0.991 - ETA: 0s - loss: 0.0397 - acc: 0.988 - ETA: 0s - loss: 0.0374 - acc: 0.989 - 0s 354us/step - loss: 0.0347 - acc: 0.9898\n",
      "Epoch 186/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0101 - acc: 1.000 - ETA: 0s - loss: 0.0258 - acc: 0.994 - ETA: 0s - loss: 0.0393 - acc: 0.991 - ETA: 0s - loss: 0.0425 - acc: 0.992 - ETA: 0s - loss: 0.0397 - acc: 0.992 - 0s 365us/step - loss: 0.0382 - acc: 0.9937\n",
      "Epoch 187/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0634 - acc: 0.968 - ETA: 0s - loss: 0.0381 - acc: 0.994 - ETA: 0s - loss: 0.0307 - acc: 0.994 - ETA: 0s - loss: 0.0373 - acc: 0.990 - ETA: 0s - loss: 0.0350 - acc: 0.991 - 0s 358us/step - loss: 0.0316 - acc: 0.9924\n",
      "Epoch 188/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0133 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 0.989 - ETA: 0s - loss: 0.0559 - acc: 0.983 - ETA: 0s - loss: 0.0522 - acc: 0.984 - ETA: 0s - loss: 0.0457 - acc: 0.987 - 0s 345us/step - loss: 0.0492 - acc: 0.9860\n",
      "Epoch 189/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.000 - ETA: 0s - loss: 0.0230 - acc: 0.994 - ETA: 0s - loss: 0.0200 - acc: 0.997 - ETA: 0s - loss: 0.0322 - acc: 0.993 - ETA: 0s - loss: 0.0314 - acc: 0.992 - 0s 363us/step - loss: 0.0321 - acc: 0.9937\n",
      "Epoch 190/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0405 - acc: 1.000 - ETA: 0s - loss: 0.0231 - acc: 1.000 - ETA: 0s - loss: 0.0302 - acc: 0.997 - ETA: 0s - loss: 0.0324 - acc: 0.995 - ETA: 0s - loss: 0.0319 - acc: 0.995 - 0s 357us/step - loss: 0.0378 - acc: 0.9937\n",
      "Epoch 191/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0331 - acc: 1.000 - ETA: 0s - loss: 0.0247 - acc: 1.000 - ETA: 0s - loss: 0.0232 - acc: 0.994 - ETA: 0s - loss: 0.0330 - acc: 0.992 - ETA: 0s - loss: 0.0361 - acc: 0.992 - 0s 345us/step - loss: 0.0341 - acc: 0.9924\n",
      "Epoch 192/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0486 - acc: 1.000 - ETA: 0s - loss: 0.0430 - acc: 0.989 - ETA: 0s - loss: 0.0400 - acc: 0.985 - ETA: 0s - loss: 0.0392 - acc: 0.987 - ETA: 0s - loss: 0.0484 - acc: 0.981 - ETA: 0s - loss: 0.0413 - acc: 0.985 - 0s 393us/step - loss: 0.0410 - acc: 0.9860\n",
      "Epoch 193/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0281 - acc: 1.000 - ETA: 0s - loss: 0.0299 - acc: 0.989 - ETA: 0s - loss: 0.0475 - acc: 0.980 - ETA: 0s - loss: 0.0467 - acc: 0.983 - ETA: 0s - loss: 0.0416 - acc: 0.985 - ETA: 0s - loss: 0.0453 - acc: 0.984 - 0s 377us/step - loss: 0.0447 - acc: 0.9848\n",
      "Epoch 194/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0299 - acc: 0.994 - ETA: 0s - loss: 0.0274 - acc: 0.996 - ETA: 0s - loss: 0.0359 - acc: 0.991 - ETA: 0s - loss: 0.0363 - acc: 0.992 - 0s 364us/step - loss: 0.0341 - acc: 0.9924\n",
      "Epoch 195/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0330 - acc: 0.989 - ETA: 0s - loss: 0.0274 - acc: 0.993 - ETA: 0s - loss: 0.0343 - acc: 0.991 - ETA: 0s - loss: 0.0367 - acc: 0.990 - ETA: 0s - loss: 0.0410 - acc: 0.988 - 0s 383us/step - loss: 0.0407 - acc: 0.9886\n",
      "Epoch 196/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.000 - ETA: 0s - loss: 0.0498 - acc: 0.975 - ETA: 0s - loss: 0.0339 - acc: 0.986 - ETA: 0s - loss: 0.0419 - acc: 0.985 - ETA: 0s - loss: 0.0392 - acc: 0.986 - ETA: 0s - loss: 0.0406 - acc: 0.985 - 0s 397us/step - loss: 0.0447 - acc: 0.9848\n",
      "Epoch 197/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0132 - acc: 1.000 - ETA: 0s - loss: 0.0293 - acc: 0.991 - ETA: 0s - loss: 0.0270 - acc: 0.994 - ETA: 0s - loss: 0.0271 - acc: 0.994 - 0s 360us/step - loss: 0.0296 - acc: 0.9924\n",
      "Epoch 198/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0190 - acc: 1.000 - ETA: 0s - loss: 0.0292 - acc: 0.991 - ETA: 0s - loss: 0.0277 - acc: 0.994 - ETA: 0s - loss: 0.0257 - acc: 0.995 - 0s 353us/step - loss: 0.0244 - acc: 0.9949\n",
      "Epoch 199/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0180 - acc: 1.000 - ETA: 0s - loss: 0.0103 - acc: 1.000 - ETA: 0s - loss: 0.0111 - acc: 1.000 - ETA: 0s - loss: 0.0138 - acc: 0.996 - ETA: 0s - loss: 0.0280 - acc: 0.991 - 0s 355us/step - loss: 0.0319 - acc: 0.9911\n",
      "Epoch 200/200\n",
      "788/788 [==============================] - ETA: 0s - loss: 0.0569 - acc: 0.968 - ETA: 0s - loss: 0.0279 - acc: 0.991 - ETA: 0s - loss: 0.0280 - acc: 0.989 - ETA: 0s - loss: 0.0225 - acc: 0.992 - ETA: 0s - loss: 0.0338 - acc: 0.988 - 0s 344us/step - loss: 0.0325 - acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to 'c:\\mie451\\assignment-cai-nicolwon\\assignment\\models\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.policies.fallback import FallbackPolicy\n",
    "\n",
    "fallback = FallbackPolicy(fallback_action_name=\"action_default_fallback\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.2)\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "# loading our training dialogues\n",
    "training_data = agent.load_data('nlu_data/stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Interaction Demo\n",
    "\n",
    "Provide the required sections as described in the handout.\n",
    "\n",
    "Start action server: python -m rasa_core_sdk.endpoint --actions actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sender_id': 'sender_id',\n",
       " 'slots': {'country': None, 'record': None, 'year': None, 'year_range': None},\n",
       " 'latest_message': {'intent': {}, 'entities': [], 'text': None},\n",
       " 'latest_event_time': 1543558863.216981,\n",
       " 'followup_action': None,\n",
       " 'paused': False,\n",
       " 'events': None,\n",
       " 'latest_input_channel': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Any simple one-step interaction requiring at least one slot filler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) \n",
    "Query - intent:presence_check - check if the dataset has data on a certain country\n",
    "\n",
    "Slot fillers required - country\n",
    "\n",
    "Supported paths - presence_check --> thanks --> goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "#### nlu_data/intents.md\n",
    "\n",
    "intent:presence_check\n",
    "- ecological footprint data on [China](country)?\n",
    "- is there info on [Pakistan](country)?\n",
    "- are there measures on [Zimbabwe](country)'s ecological footprint?\n",
    "\n",
    "intent:thanks\n",
    "- thanks\n",
    "- thank you\n",
    "- thank you very much\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "- thank you loads\n",
    "- tnx\n",
    "\n",
    "intent:goodbye\n",
    "- see you\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "- good bye\n",
    "- stop\n",
    "\n",
    "#### nlu_data/stories.md\n",
    "\n",
    "Thanks\n",
    "* thanks\n",
    "    - utter_np\n",
    "\n",
    "Goodbye\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Fallback\n",
    "* fallback\n",
    "    - utter_fallback\n",
    "\n",
    "Path 6\n",
    "* presence_check{\"country\": \"Latvia\"}\n",
    "    - action_check_presence\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "#### actions.py\n",
    "\n",
    "class PresenceAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_check_presence\"\n",
    "    \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        country = tracker.get_slot('country')\n",
    "        print(country)\n",
    "\n",
    "        presence = len(data[data.country.str.lower() == country.lower()]) > 0\n",
    "\n",
    "        if presence is True:\n",
    "            dispatcher.utter_message(\"There exists data for {}'s ecological footprint!\".format(country))\n",
    "        else:\n",
    "            dispatcher.utter_message(\"There is no data on {}'s ecological footprint!\".format(country))\n",
    "\n",
    "#### domain.yml\n",
    "\n",
    "intents: \n",
    "- presence_check\n",
    "\n",
    "slots:\n",
    "  \n",
    "  country:\n",
    "    type: text\n",
    "    \n",
    "entities:\n",
    "  - country\n",
    "  \n",
    "actions:\n",
    "  - action_check_presence\n",
    "  - utter_np\n",
    "  - utter_goodbye\n",
    "  \n",
    "templates:\n",
    "\n",
    "utter_goodbye:\n",
    "  - text: \"Bye!\"\n",
    "\n",
    "utter_np:\n",
    "  - text: \"No Problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.42163502795040275\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.42163502795040275\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.20830170103754486\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.14314926737283978\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.11499450165803082\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05225639419035842\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.024826912344413987\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.013213800036242226\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.011523950724546171\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.0100984446856201\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n",
      "Hey!!\n",
      "is there info on kenya?\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"presence_check\",\n",
      "    \"confidence\": 0.33301083378921853\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 17,\n",
      "      \"end\": 22,\n",
      "      \"value\": \"kenya\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.5899618643994189,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.33301083378921853\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.13944829519968358\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.11155072091951553\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.08840547482664407\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.08086400563552408\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08077611400585845\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.07262604917263862\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.054346507579340016\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.03897199887157728\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"is there info on kenya?\"\n",
      "}\n",
      "There exists data for kenya's ecological footprint!\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "A different interaction that contains at least one slot filler and at least two paths (possible\n",
    "branches in the interaction sequence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) \n",
    "Query - intent:results_query - Retrieve the total hectares consumed/produced by a country's ecological footprint in a specific year and from a specific record type. The data has 5 record types - Biocapacity (Biocap), Ecological Footprint Exports, Inports, Produced, Consumed (EFExports, EFImports, EFProd, EFCons) - and each record type has two possible measures - global hectares per capita (PerCap) and total global hectares (TotGHA).\n",
    "\n",
    "Slot fillers required - country, year, record\n",
    "\n",
    "Supported paths \n",
    "- results_query(country, year, record) --> thanks --> goodbye\n",
    "- results_query --> inform(country) --> inform(year) --> inform(record) --> thanks --> goodbye\n",
    "- results_query(country) --> inform(year) --> inform(record) --> thanks --> goodbye\n",
    "- results_query(year) --> inform(country) --> inform(record) --> thanks --> goodbye\n",
    "- results_query(country, year) --> inform(record) --> thanks --> goodbye\n",
    "- results_query(record, year) --> inform(country) --> thanks --> goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "#### nlu_data/intents.md\n",
    "\n",
    "intent:results_query\n",
    "- give me the [EFConsTotGHA](record) results for [Russia](country) in [1996](year)\n",
    "- do you have record data on [Brazil](country)\n",
    "- do you know about [Egypt](country)\n",
    "- how many hectares did [New Zealand](country) consume in [2004](year)?\n",
    "- what was the [BioCapTotGHA](record) for [country]?\n",
    "- what was the [EFProdPerCap](record) footprint in [2007](year) for [Australia](country)?\n",
    "- I want information for [Serbia](country)\n",
    "- data for [Spain](country)\n",
    "- [EFImportsPerCap](record) footprint in [1998](year)\n",
    "\n",
    "intent:inform\n",
    "- I want to know about [France](country)\n",
    "- [Japan](country)\n",
    "- [1992](year)\n",
    "- [BiocapPerCap](record)\n",
    "- [EFExportsTotGHA](record)\n",
    "- [2001](year)\n",
    "- [South Korea](country)\n",
    "- [1990-1993](year_range)\n",
    "- [1970-1986](year_range)\n",
    "- [Malaysia](country)\n",
    "\n",
    "intent:thanks\n",
    "- thanks\n",
    "- thank you\n",
    "- thank you very much\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "- thank you loads\n",
    "- tnx\n",
    "\n",
    "intent:goodbye\n",
    "- see you\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "- good bye\n",
    "- stop\n",
    "\n",
    "#### nlu_data/stories.md\n",
    "\n",
    "Thanks\n",
    "* thanks\n",
    "    - utter_np\n",
    "\n",
    "Goodbye\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Fallback\n",
    "* fallback\n",
    "    - utter_fallback\n",
    "\n",
    "Path 1\n",
    "* greet\n",
    "    - utter_greet\n",
    "* results_query\n",
    "    - utter_what_country\n",
    "* inform{\"country\":\"china\"}\n",
    "    - utter_what_year\n",
    "* inform{\"year\":\"2001\"}\n",
    "    - utter_what_record\n",
    "* inform{\"record\":\"EFImportsPerCap\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Path 2 \n",
    "* results_query{\"country\": \"venezuela\"}\n",
    "    - utter_what_year\n",
    "* inform{\"year\":\"2001\"}\n",
    "    - utter_what_record\n",
    "* inform{\"record\":\"EFImportsPerCap\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "    \n",
    "Path 3 \n",
    "* results_query{\"record\": \"EFExportsPerCap\"}\n",
    "    - utter_what_country\n",
    "* inform{\"country\": \"Chile\"}\n",
    "    - utter_what_year\n",
    "* inform{\"year\":\"2002\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "    \n",
    "Path 4 \n",
    "* results_query{\"country\": \"venezuela\", \"year\": \"1998\"}\n",
    "    - utter_what_record\n",
    "* inform{\"record\":\"EFImportsPerCap\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Path 5 \n",
    "* results_query{\"record\": \"EFProdTotGHA\", \"year\": \"1998\"}\n",
    "    - utter_what_country\n",
    "* inform{\"country\":\"Kenya\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Path 7\n",
    "* results_query{\"country\": \"Portugal\", \"year\": \"1996\", \"record\": \"EFProdPerCap\"}\n",
    "    - action_get_results\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "#### actions.py\n",
    "\n",
    "data = pd.read_csv(\"data/NFA_2018.csv\").astype(str)\n",
    "\n",
    "record_dict = {'biocappercap': 'Biocapacity per capita',\n",
    "               'biocaptotgha': 'Biocapacity in total global hectares',\n",
    "               'efconspercap': 'Ecological Footprint Consumption per capita',\n",
    "               'efconstotgha': 'Ecological Footprint Consumption in total global hectares',\n",
    "               'efprodpercap': 'Ecological Footprint Production per capita',\n",
    "               'efprodtotgha': 'Ecological Footprint Production in total global hectares',\n",
    "               'efexportspercap': 'Ecological Footprint Exports per capita',\n",
    "               'efexportstotgha': 'Ecological Footprint Exports in total global hectares',\n",
    "               'efimportspercap': 'Ecological Footprint Imports per capita',\n",
    "               'efimportstotgha': 'Ecological Footprint Imports in total global hectares'}\n",
    "\n",
    "class WinsAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_get_results\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        country = tracker.get_slot('country')\n",
    "        year = tracker.get_slot('year')\n",
    "        record = tracker.get_slot('record')\n",
    "        \n",
    "        results = data[(data.country.str.lower() == country.lower()) & (data.record.str.lower() == record.lower()) & (data.year.str.lower() == year.lower())]\n",
    "        \n",
    "        dispatcher.utter_message(\"{} for {} in {} was {} hectares.\".format(record_dict[record], country, year, np.asscalar(results.total)))\n",
    "\n",
    "#### domain.yml\n",
    "\n",
    "intents: \n",
    "- greet \n",
    "- goodbye\n",
    "- affirm\n",
    "- deny\n",
    "- thanks\n",
    "- inform\n",
    "- summary_query\n",
    "\n",
    "slots:\n",
    "\n",
    "  country:\n",
    "    type: text\n",
    "    \n",
    "  year_range:\n",
    "    type: text\n",
    "\n",
    "    \n",
    "entities:\n",
    "  - country\n",
    "  - year_range\n",
    "  \n",
    "actions:\n",
    "  - utter_greet\n",
    "  - utter_goodbye\n",
    "  - utter_sure\n",
    "  - utter_ok\n",
    "  - utter_np\n",
    "  - utter_what_country\n",
    "  - utter_what_year_range\n",
    "  - action_get_reserve\n",
    "  - utter_fallback\n",
    "  \n",
    "templates:\n",
    "\n",
    "utter_greet:\n",
    "- text: \"Hello!\"\n",
    "- text: \"Hey!!\"\n",
    "\n",
    "utter_goodbye:\n",
    "- text: \"Bye!\"\n",
    "\n",
    "utter_sure:\n",
    "- text: \"Are you sure?\"\n",
    "\n",
    "utter_ok:\n",
    "- text: \"OK\"\n",
    "\n",
    "utter_np:\n",
    "- text: \"No Problem\"\n",
    "\n",
    "utter_what_country:\n",
    "- text: \"What country?\"\n",
    "\n",
    "utter_what_year_range:\n",
    "- text: \"What year range?\"\n",
    "- text: \"From what year to what year?\"\n",
    "\n",
    "utter_fallback:\n",
    "- text: \"Sorry I didn't understand.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "do you have data on malaysia?\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"results_query\",\n",
      "    \"confidence\": 0.39775920126378894\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 20,\n",
      "      \"end\": 28,\n",
      "      \"value\": \"malaysia\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.993641961582165,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.39775920126378894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.12942334089238078\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.11237285072816555\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.07990432095657826\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.07978104465819344\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.06491674140414977\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.055961788619077156\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.052568607887740086\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.027312103589925554\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"do you have data on malaysia?\"\n",
      "}\n",
      "What year?\n",
      "1990\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.43622703190406664\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 0,\n",
      "      \"end\": 4,\n",
      "      \"value\": \"1990\",\n",
      "      \"entity\": \"year\",\n",
      "      \"confidence\": 0.4005141578001081,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.43622703190406664\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.1368506656627774\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.11433475995436276\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09208599741056409\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.07143572220716252\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.05486817618569887\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.03562769942951043\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.033943253988120335\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.02462669325773682\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"1990\"\n",
      "}\n",
      "What record type?\n",
      "biocappercap\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.4937172888260111\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 0,\n",
      "      \"end\": 12,\n",
      "      \"value\": \"biocappercap\",\n",
      "      \"entity\": \"record\",\n",
      "      \"confidence\": 0.8339646566717892,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.4937172888260111\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.12620603456241142\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.08812156003245239\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.081852308563859\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.07491559915849696\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.05421027817203018\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.04090420761271461\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.02311297239564622\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.01695975067637765\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"biocappercap\"\n",
      "}\n",
      "Biocapacity per capita for malaysia in 1990 was 3.5238731760000004 hectares.\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "what was the efconstotgha footprint in 1993 for armenia?\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"results_query\",\n",
      "    \"confidence\": 0.4026511040165984\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 13,\n",
      "      \"end\": 25,\n",
      "      \"value\": \"efconstotgha\",\n",
      "      \"entity\": \"record\",\n",
      "      \"confidence\": 0.9418617962975917,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 39,\n",
      "      \"end\": 43,\n",
      "      \"value\": \"1993\",\n",
      "      \"entity\": \"year\",\n",
      "      \"confidence\": 0.6747118582132801,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 48,\n",
      "      \"end\": 55,\n",
      "      \"value\": \"armenia\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.9073924064431201,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.4026511040165984\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.11161604435393394\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.1042625919574811\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.09973671946685672\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.08528581009199024\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05953325274685077\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.055891349390244344\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.04758925587252857\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.03343387210351603\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"what was the efconstotgha footprint in 1993 for armenia?\"\n",
      "}\n",
      "Ecological Footprint Consumption in total global hectares for armenia in 1993 was 3903530.4469999997 hectares.\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "A different complex interaction that contains at least two slot fillers and at least three\n",
    "paths. This complex interaction must contain some aggregate analysis of the data according\n",
    "to constraints specified by the user, i.e., it cannot involve a simple lookup of one entry in\n",
    "a table. For example, a complex question involving three slot fillers: “Which team did\n",
    "Manchester United have the best winning percentage against between 2007 and 2017?’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) \n",
    "Query - intent:summary_query - see when a country had the best ecological reserve (Biocapacity - ecological footprint consumed) in a given range of years\n",
    "\n",
    "Slot fillers required - country, year-range\n",
    "\n",
    "Supported paths \n",
    "- summary_query(country, year_range) --> thanks --> goodbye\n",
    "- summary_query(country) --> inform(year_range) --> thanks --> goodbye\n",
    "- summary_query(country) --> inform(year_range) --> inform(country) --> thanks --> goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "#### nlu_data/intents.md\n",
    "\n",
    "intent:summary_query\n",
    "- tell me more about [Mexico](country)'s ecological reserve\n",
    "- give me a summary of [Madagascar](country)'s ecological reserves from [2001-2008](year_range)\n",
    "- I want to know more about [Israel](country)'s ecological reserves\n",
    "- I want to learn more about ecological reserves\n",
    "- info on ecological reserves\n",
    "- ecological reserves for [Malaysia]\n",
    "\n",
    "intent:inform\n",
    "- I want to know about [France](country)\n",
    "- [Japan](country)\n",
    "- [1992](year)\n",
    "- [BiocapPerCap](record)\n",
    "- [EFExportsTotGHA](record)\n",
    "- [2001](year)\n",
    "- [South Korea](country)\n",
    "- [1990-1993](year_range)\n",
    "- [1970-1986](year_range)\n",
    "- [Malaysia](country)\n",
    "\n",
    "intent:thanks\n",
    "- thanks\n",
    "- thank you\n",
    "- thank you very much\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "- thank you loads\n",
    "- tnx\n",
    "\n",
    "intent:goodbye\n",
    "- see you\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "- good bye\n",
    "- stop\n",
    "\n",
    "#### nlu_data/stories.md\n",
    "\n",
    "Thanks\n",
    "* thanks\n",
    "    - utter_np\n",
    "\n",
    "Goodbye\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Fallback\n",
    "* fallback\n",
    "    - utter_fallback\n",
    "\n",
    "Path 8\n",
    "* summary_query{\"country\": \"Cyprus\", \"year_range\": \"1982-1986\"}\n",
    "    - action_get_reserve\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Path 9\n",
    "* summary_query{\"country\": \"Bolivia\"}\n",
    "    - utter_what_year_range\n",
    "* inform{\"year_range\": \"1980-1999\"}\n",
    "    - action_get_reserve\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "Path 10\n",
    "* summary_query\n",
    "    - utter_what_year_range\n",
    "* inform{\"year_range\": \"1980-1999\"}\n",
    "    - utter_what_country\n",
    "* inform{\"country\": \"Malaysia\"}\n",
    "    - action_get_reserve\n",
    "* thanks\n",
    "    - utter_np\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - action_restart\n",
    "\n",
    "#### actions.py\n",
    "\n",
    "class ComplexAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_get_reserve\"\n",
    "    \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        print('Entered')\n",
    "        country = tracker.get_slot('country')\n",
    "        print(country)\n",
    "        yearRange = tracker.get_slot('year_range')\n",
    "        print(yearRange)\n",
    "        \n",
    "        minYear, maxYear = yearRange.replace(' ', '').split('-')\n",
    "        print(minYear)\n",
    "        print(maxYear)\n",
    "        \n",
    "        yearlyBCTGFull = data[(data.country.str.lower() == country) & (data.record == 'BiocapTotGHA') & (pd.to_numeric(data.year, downcast='integer') >= int(minYear)) & (pd.to_numeric(data.year, downcast='integer') <= int(maxYear))]\n",
    "        yearlyEFTGFull = data[(data.country.str.lower() == country) & (data.record == 'EFConsTotGHA') & (pd.to_numeric(data.year, downcast='integer') >= int(minYear)) & (pd.to_numeric(data.year, downcast='integer') <= int(maxYear))]\n",
    "        \n",
    "        yearlyBCTF = pd.to_numeric(pd.Series(yearlyBCTGFull.total.values, index = yearlyBCTGFull.year))\n",
    "        yearlyEFTG = pd.to_numeric(pd.Series(yearlyEFTGFull.total.values, index = yearlyEFTGFull.year))\n",
    "        \n",
    "        maxER = (yearlyBCTF - yearlyEFTG).nlargest(1)\n",
    "        minER = (yearlyBCTF - yearlyEFTG).nsmallest(1)\n",
    "        \n",
    "        dispatcher.utter_message(\"A country's ecological reserve is the biocapacity of the area available minus the ecological footprint generated by human consumption.\\n Between the years of {} and {}, {} had the greatest ecological reserve in {} with {} hectares, but had the smallest ecological reserve in {} with {} hectares.\".format(minYear, maxYear, country, maxER.index[0], maxER.values[0], minER.index[0], minER.values[0]))\n",
    "\n",
    "#### domain.yml\n",
    "\n",
    "intents: \n",
    "- results_query\n",
    "- inform\n",
    "- thanks\n",
    "\n",
    "slots:\n",
    "\n",
    "  country:\n",
    "    type: text\n",
    "    \n",
    "  year:\n",
    "    type: text\n",
    "    \n",
    "  record:\n",
    "    type: text\n",
    "    \n",
    "entities:\n",
    "  - country\n",
    "  - year\n",
    "  - record\n",
    "  \n",
    "actions:\n",
    "  - utter_greet\n",
    "  - utter_goodbye\n",
    "  - utter_sure\n",
    "  - utter_ok\n",
    "  - utter_np\n",
    "  - utter_what_country\n",
    "  - utter_what_year\n",
    "  - utter_what_record\n",
    "  - action_get_results\n",
    "  \n",
    "templates:\n",
    "\n",
    "utter_greet:\n",
    "- text: \"Hello!\"\n",
    "- text: \"Hey!!\"\n",
    "\n",
    "utter_goodbye:\n",
    "- text: \"Bye!\"\n",
    "\n",
    "utter_sure:\n",
    "- text: \"Are you sure?\"\n",
    "\n",
    "utter_ok:\n",
    "- text: \"OK\"\n",
    "\n",
    "utter_np:\n",
    "- text: \"No Problem\"\n",
    "\n",
    "utter_what_country:\n",
    "- text: \"What country?\"\n",
    "\n",
    "utter_what_year:\n",
    "- text: \"What year?\"\n",
    "\n",
    "utter_what_record:\n",
    "- text: \"What record type?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "info on ecological reserves\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"summary_query\",\n",
      "    \"confidence\": 0.44686849481498747\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.44686849481498747\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.13775261852291715\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.09757168479506259\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.09536976497168649\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.07089761454031471\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05173266803491045\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.04610109298595743\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.037647397719183205\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.016058663614980633\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"info on ecological reserves\"\n",
      "}\n",
      "From what year to what year?\n",
      "1980-1990\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.48737533890907986\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 0,\n",
      "      \"end\": 9,\n",
      "      \"value\": \"1980 - 1990\",\n",
      "      \"entity\": \"year_range\",\n",
      "      \"confidence\": 0.7865877824704083,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.48737533890907986\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.11086485151808974\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.10673977128625402\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.07305607318911579\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.07095020823273092\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.047659026274341196\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.04115796646331257\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.031451889530185434\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.030744874596890865\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"1980-1990\"\n",
      "}\n",
      "What country?\n",
      "malaysia\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.46739189402545817\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 0,\n",
      "      \"end\": 8,\n",
      "      \"value\": \"malaysia\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.6962200659284973,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.46739189402545817\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.13121087909978751\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1309169294065277\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.07441487423842003\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.07082425015346396\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.04934537004011759\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.02864851030669411\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.02497330408394602\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.022273988645584608\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"malaysia\"\n",
      "}\n",
      "A country's ecological reserve is the biocapacity of the area available minus the ecological footprint generated by human consumption.\n",
      " Between the years of 1980 and 1990, malaysia had the greatest ecological reserve in 1986 with 27429976.1 hectares, but had the smallest ecological reserve in 1990 with 12898153.79 hectares.\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "tell me more about armenia's ecological reserves\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"summary_query\",\n",
      "    \"confidence\": 0.5129614394036204\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 19,\n",
      "      \"end\": 26,\n",
      "      \"value\": \"armenia\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.9856976280845215,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.5129614394036204\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.08423390421946703\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.08399073420933094\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.08393306280537663\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.06472620113429721\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.057946465223645854\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.056966412191351824\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.03373807778619602\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.02150370302671384\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"tell me more about armenia's ecological reserves\"\n",
      "}\n",
      "What year range?\n",
      "1994-1999\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.4916381048264616\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 0,\n",
      "      \"end\": 9,\n",
      "      \"value\": \"1994 - 1999\",\n",
      "      \"entity\": \"year_range\",\n",
      "      \"confidence\": 0.7819363463499429,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.4916381048264616\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.1277306169000402\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.1272094859945661\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.06791770507389559\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.04801358535866317\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.04720769622832217\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.038678683448180505\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.0263450696262809\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.02525905254358962\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"1994-1999\"\n",
      "}\n",
      "A country's ecological reserve is the biocapacity of the area available minus the ecological footprint generated by human consumption.\n",
      " Between the years of 1994 and 1999, armenia had the greatest ecological reserve in 1996 with -1693440.9740000002 hectares, but had the smallest ecological reserve in 1994 with -2219235.733 hectares.\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "give me a summary of france's ecological reserves from 1985-1990\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"summary_query\",\n",
      "    \"confidence\": 0.4129187444013156\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 21,\n",
      "      \"end\": 27,\n",
      "      \"value\": \"france\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.5321699909435714,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 55,\n",
      "      \"end\": 64,\n",
      "      \"value\": \"1985 - 1990\",\n",
      "      \"entity\": \"year_range\",\n",
      "      \"confidence\": 0.7891537338578335,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.4129187444013156\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.12891941412576624\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.1268321840089193\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.0860888235653436\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.06763518528371051\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05622512498270976\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.04762823778132076\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.04517899463533222\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.02857329121558194\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"give me a summary of france's ecological reserves from 1985-1990\"\n",
      "}\n",
      "A country's ecological reserve is the biocapacity of the area available minus the ecological footprint generated by human consumption.\n",
      " Between the years of 1985 and 1990, france had the greatest ecological reserve in 1985 with -116970739.80000001 hectares, but had the smallest ecological reserve in 1990 with -154518250.6 hectares.\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Logic Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resetting slots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.42163502795040275\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.42163502795040275\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.20830170103754486\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.14314926737283978\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.11499450165803082\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05225639419035842\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.024826912344413987\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.013213800036242226\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.011523950724546171\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.0100984446856201\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n",
      "Hello!\n",
      "is there info on pakistan?\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"presence_check\",\n",
      "    \"confidence\": 0.38212429948605414\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 17,\n",
      "      \"end\": 25,\n",
      "      \"value\": \"pakistan\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.8878085082429646,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.38212429948605414\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.10756093886809329\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.09874147090912919\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.09225343900828299\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.08811595252438169\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.07356893505780071\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.068287914674736\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.05374765410214124\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.03559939536938046\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"is there info on pakistan?\"\n",
      "}\n",
      "There exists data for pakistan's ecological footprint!\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "is there info on canada?\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"presence_check\",\n",
      "    \"confidence\": 0.3542428652169965\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 17,\n",
      "      \"end\": 23,\n",
      "      \"value\": \"canada\",\n",
      "      \"entity\": \"country\",\n",
      "      \"confidence\": 0.5899618643994189,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.3542428652169965\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.12042735337801383\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.10467023180815356\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.09436678733537113\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.0808672651068923\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.07913943583596209\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.07799369935638263\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.048995596582059125\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.0392967653801687\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"is there info on canada?\"\n",
      "}\n",
      "There exists data for canada's ecological footprint!\n",
      "thanks\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"thanks\",\n",
      "    \"confidence\": 0.4767870048346722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.4767870048346722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.15786301461442473\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09219475184034302\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.06710004752923576\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.06622707934625584\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.05233478839986501\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.037584275596788876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.02790681800914129\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.022002219829272966\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"thanks\"\n",
      "}\n",
      "No Problem\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fallback Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.42163502795040275\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.42163502795040275\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.20830170103754486\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.14314926737283978\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.11499450165803082\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05225639419035842\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.024826912344413987\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.013213800036242226\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.011523950724546171\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.0100984446856201\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n",
      "Hello!\n",
      "trying again\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"deny\",\n",
      "    \"confidence\": 0.21631027221009794\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.21631027221009794\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.19458746069566307\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.19183793674206415\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.13891885445402744\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.10356646858946258\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.05239395318228929\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.03595156960586261\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.03546245069666851\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.03097103382386415\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"trying again\"\n",
      "}\n",
      "Sorry I didn't understand.\n",
      "bye\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.5290133891277825\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.5290133891277825\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.1872331842061182\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.08935978717126102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.05487018195585431\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.054197754460458894\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.053480511395346375\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"results_query\",\n",
      "      \"confidence\": 0.011595082597473967\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"presence_check\",\n",
      "      \"confidence\": 0.01061749495867067\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"summary_query\",\n",
      "      \"confidence\": 0.009632614127033909\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n",
      "Bye!\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mie451-assignment-ci]",
   "language": "python",
   "name": "conda-env-mie451-assignment-ci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
